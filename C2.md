## **Chapter 2: Literature Review**

This chapter provides a critical and extensive review of the existing literature pertinent to the study of context effects in episodic memory, with a particular focus on recognition memory and computational modeling approaches. The overarching aim is to establish a robust theoretical and empirical foundation for the research undertaken in this dissertation, delving deeply into the nuances and complexities of each area. The review begins by meticulously examining major theories of episodic memory, carefully differentiating between dual-process and single-process accounts of recognition, exploring their historical development, core tenets, supporting evidence, and unresolved debates. It then transitions into a detailed exploration of how various influential computational models of memory have conceptualized, represented, and implemented the multifaceted construct of context. This section will not only describe the models but also critically evaluate their strengths and limitations in capturing the dynamic nature of context.

Subsequently, a comprehensive survey of key empirical findings that demonstrate the profound and often intricate impact of context on memory performance is presented. This will cover a wide array of phenomena, including but not limited to list length effects, the nuances of serial position curves (primacy and recency effects), the pervasive issue of output interference, the foundational principles of context change and reinstatement, and the critical role of temporal information and contextual drift in shaping memory. Common recognition memory paradigms, such as item and associative recognition, will be discussed in depth, along with a thorough analysis of how different types of foil items can influence memory judgments and what these influences reveal about underlying cognitive processes.

The chapter will then consider the significant advantages and specific applications of computational modeling as an indispensable tool in memory research. Particular emphasis will be placed on previous efforts to model context effects using the Retrieving Effectively from Memory (REM) framework, examining its evolution and the specific contributions of its variants. Finally, this extensive synthesis of the theoretical, empirical, and computational literature will culminate in the precise identification of specific gaps, unresolved questions, and methodological challenges. This critical analysis will thereby provide a clear and compelling rationale for the aims and objectives of the current dissertation, particularly underscoring the pressing need for an extended and refined REM-based model capable of addressing the sophisticated complexities of dynamic context in episodic memory.

### **2.1. Theories of Episodic Memory**

Understanding the intricate ways in which context influences episodic memory necessitates a foundational grasp of the theoretical frameworks that describe the underlying processes of memory retrieval. This is particularly crucial in the domain of recognition memory, the cognitive ability to determine whether a stimulus has been encountered previously. The nature of recognition memory has been a central topic of debate in cognitive psychology for decades, primarily revolving around a fundamental question: is recognition supported by a single, unitary underlying process, or by two (or potentially more) distinct, qualitatively different processes? This distinction has profound implications for how we conceptualize memory, interpret experimental findings, and develop computational models.

#### **2.1.1. Dual-process theories (familiarity and recollection)**

A prominent and highly influential class of theories in the study of recognition memory posits that judgments of prior occurrence are not monolithic but are instead supported by two qualitatively distinct and functionally independent (or at least dissociable) underlying processes: **familiarity** and **recollection**.1 This perspective, championed and elaborated by numerous researchers including Jacoby, Yonelinas, and Mandler, suggests that these two routes to recognition provide different kinds of information and operate under different principles.1**Familiarity**, in this framework, is often characterized as a relatively fast-acting, perhaps even automatic, process that provides a general, acontextual sense of "knowing" or an assessment of an item's prior occurrence without the retrieval of specific details about the encoding episode.1 It's often described as a feeling of perceptual fluency or a global memory signal. For example, upon seeing a face, one might experience a strong sense of familiarity—a feeling that the face has been seen before—without being able to place where or when the prior encounter occurred. Computationally, familiarity is frequently conceptualized as a continuous signal-strength variable, often modeled using principles derived from signal detection theory.2 According to this view, each item, whether old or new, possesses a certain level of familiarity. Old items, on average, are assumed to have higher familiarity values than new items, but the distributions of familiarity for old and new items typically overlap. A recognition decision based on familiarity is then made by assessing whether an item's familiarity value surpasses a predetermined response criterion.2 If it does, the item is endorsed as "old"; if not, it's judged as "new." This process is thought to be relatively effortless and does not necessarily involve conscious retrieval of the learning episode.In stark contrast, **recollection** is typically conceptualized as a slower, more effortful, and attention-demanding process that involves the conscious retrieval of specific qualitative information about the learning event itself.1 This retrieved information is often rich in contextual detail, such as the spatial location where an item was encountered (e.g., "I saw this word on the left side of the screen"), the temporal context (e.g., "This word was in the first study list"), or associative information (e.g., "This word was paired with that image"). Recollection is not merely a stronger version of familiarity; it is considered a qualitatively different kind of memory experience, often associated with the subjective feeling of "remembering" a specific past episode. Unlike the continuous nature often ascribed to familiarity, recollection is frequently viewed as a threshold process: an individual either successfully retrieves specific episodic details associated with an item, or they do not.2 If recollection is successful, it can provide highly diagnostic information for a recognition judgment.When both familiarity and recollection contribute to a recognition decision, their interplay is a key aspect of dual-process models. Often, recollection is thought to provide more definitive and reliable evidence for prior occurrence. If an individual can recollect specific details of an item's encoding, they are highly likely to judge it as "old," potentially overriding a weaker or ambiguous familiarity signal.2 The dual-process signal detection (DPSD) model, for instance, formalizes these ideas by assuming that familiarity follows an equal-variance Gaussian signal-detection model, providing a continuous measure, while recollection operates as a discrete retrieval state, succeeding with a certain probability.2 If recollection occurs, the item is confidently identified as old; if recollection fails, the decision relies solely on the familiarity signal compared against a criterion.

The distinction between familiarity and recollection is particularly germane to the study of context because contextual information is, by its very definition, central to the concept of recollection. The ability to retrieve where, when, or how an item was learned is the hallmark of a recollective experience. Consequently, experimental manipulations that specifically alter the encoding or retrieval context—such as changing the physical environment between study and test, altering the participant's internal state (e.g., mood), or varying the temporal lag between study and test—are predicted by dual-process theories to primarily impact the likelihood or success of the recollection process. Familiarity, being a more general and potentially acontextual assessment of prior occurrence, might be less susceptible to such contextual changes, or it might be affected in different ways or to a lesser degree. This theoretical framework thus provides a valuable and nuanced lens through which to interpret the often complex effects of contextual manipulations on recognition memory performance, allowing researchers to probe which underlying process is being predominantly affected.

From a computational modeling perspective, instantiating these two qualitatively different processes presents a significant and interesting challenge. Some models might primarily capture familiarity-like strength assessments, for example, early global matching models which compute an overall match between a probe and the contents of memory. Other models, or extensions thereof, attempt to explicitly model the retrieval of specific contextual features, an operation that aligns more closely with the concept of recollection. The two-step decision process described in the specific REM-based model 3 that is a focus of this dissertation—where an initial "Context Filtering" stage occurs before a "Content Feature Evaluation" stage—could be interpreted within such a dual-process framework. The context filtering step, which relies on matching both changing (CC_ℓ) and unchanging (UC) context features of a memory trace to those of the probe, might serve as a computational analogue for a recollection attempt. This stage essentially checks if the item’s specific encoding context can be successfully retrieved or matched to the current retrieval context. If an item's trace passes this contextual check (i.e., its context match exceeds a threshold `τ` 3), the subsequent content evaluation, based on item-specific features, could reflect a familiarity assessment or further evidence accumulation based on the item's intrinsic properties.Evidence supporting dual-process theories comes from a variety of sources. Behavioral studies using the remember/know procedure (where participants report whether their recognition judgment is accompanied by a specific recollection of the learning episode – "remember" – or just a feeling of familiarity – "know") often show dissociations between these two types of judgments under different experimental manipulations. For example, variables like divided attention at encoding or changes in perceptual modality between study and test tend to affect "remember" responses (recollection) more than "know" responses (familiarity). Receiver Operating Characteristic (ROC) analyses, which plot hit rates against false alarm rates across different levels of response confidence, often yield curvilinear and asymmetrical shapes that are argued to be better fit by models incorporating both a continuous familiarity process and a threshold recollection process than by single-process models alone.2 Neuropsychological studies of patients with selective brain damage have also provided support. For instance, some studies suggest that damage to the hippocampus disproportionately impairs recollection, while damage to adjacent perirhinal cortex might more severely affect familiarity, although this anatomical mapping is still a subject of considerable debate.1 Functional neuroimaging studies (fMRI and ERP) have also reported distinct patterns of brain activity associated with familiarity-based versus recollection-based recognition judgments.1

Despite the wealth of supporting evidence, dual-process theories are not without their critics and ongoing debates. One key area of contention is the precise nature of familiarity – whether it is truly acontextual or if it can carry some implicit contextual information. Another is the strict independence often assumed between recollection and familiarity; some researchers argue for more interactive or cascaded relationships. Nevertheless, the dual-process framework has been exceptionally generative, providing a rich conceptual toolkit for dissecting the complexities of recognition memory and, crucially for this dissertation, for understanding the multifaceted role of context.

#### **2.1.2. Single-process theories**

Contrasting sharply with dual-process accounts, single-process theories of recognition memory propose that judgments about whether a stimulus has been encountered previously are based on a unitary, continuous dimension of memory strength or evidence, rather than reflecting the operation of two distinct underlying retrieval processes.4 These theories, often deeply rooted in the principles of signal detection theory (SDT), argue that the phenomenological experiences often labeled as "remembering" (which dual-process theorists equate with recollection) and "knowing" (equated with familiarity) do not necessarily reflect separate retrieval mechanisms. Instead, they are proposed to represent different points along a single continuum of memory strength or the amount of evidence retrieved.5 From this perspective, a "remember" judgment might correspond to a very high level of memory strength, indicating a rich and detailed memory trace, while a "know" judgment might reflect a moderate level of memory strength that, while lower, still exceeds the criterion necessary for judging an item as old.According to this unitary perspective, the "strength of evidence" for an item's prior occurrence can be influenced by a multitude of factors, including the richness and distinctiveness of the encoded information. Crucially, this encoded information naturally includes contextual details.5 Thus, a strong memory trace, one that elicits a high strength signal, is likely to be one that is rich in both item-specific information and associated contextual details. The debate, from the single-process viewpoint, is therefore less about _whether_ contextual information contributes to recognition (it is generally accepted that it clearly does) and more about _whether_ its contribution necessitates positing a separate retrieval process that is qualitatively different from the overall assessment of memory strength.5Some single-process models explicitly incorporate the idea that the overall memory strength signal is an aggregation of information derived from various sources, including the quality of the match between the current retrieval cues (which can include context) and the stored memory trace.5 For instance, Slotnick and Dodson (2005) demonstrated that as confidence in an old/new decision (often taken as a proxy for memory strength) increases, the amount of available source recollection (i.e., memory for contextual details) also tends to increase, suggesting a correlation and interdependence rather than the operation of two independent processes.5 Similarly, other researchers have argued that what appears to be a qualitative difference between recollection and familiarity might simply reflect quantitative differences in the amount or type of information retrieved, all contributing to a single strength axis.The original formulation of the Retrieving Effectively from Memory (REM) model, as proposed by Shiffrin and Steyvers (1997), aligns more naturally with a single-process perspective.7 REM calculates the probability that a test item is "old" based on the accumulated evidence derived from matching its features (which can include both item and context features) against all stored memory traces.7 This calculated probability can be considered a continuous, strength-like value that forms the basis for the recognition decision. Indeed, many computationally specified models of recognition, including REM and other global matching models, have historically been interpreted within a single-process framework, where a single continuous variable (e.g., global match, likelihood ratio) determines the memory judgment.8While the foundational REM model operates on this principle of a unified evidence signal, its flexible feature-based architecture does not inherently preclude extensions or interpretations that might incorporate assumptions more aligned with dual-process theories. For example, one could implement different decision rules based on the match of distinct types of features (e.g., item-specific features versus context-specific features) or based on the quality and quantity of retrieved information. The specific REM-based model detailed in 3, with its sequential context filtering and content evaluation stages, could be seen as a hybrid, potentially bridging aspects of both single- and dual-process ideas, depending on how the thresholds and feature contributions are conceptualized.

The debate between single- and dual-process theories has been a long-standing and productive one in memory research. Proponents of single-process models often argue for parsimony, suggesting that dual-process models introduce unnecessary complexity if the data can be adequately explained by a single underlying dimension of strength. They might point to the difficulty in definitively proving the qualitative distinctness and independence of recollection and familiarity, and argue that many dissociations attributed to separate processes can be reinterpreted as effects on different regions of a single strength continuum or as strategic shifts in criterion placement. For example, manipulations that affect recollection more than familiarity might simply be those that have a larger impact on the upper end of the memory strength distribution.

The choice of a single- versus dual-process theoretical stance can significantly influence the architectural choices made during the development of computational models of memory. It affects how context is represented (e.g., as a special class of features contributing to a distinct process, or as features contributing to an overall strength signal) and how its influence on memory decisions is simulated (e.g., through a dedicated recollection mechanism or through its impact on the global match value). This ongoing theoretical discussion continues to shape empirical investigations and the refinement of computational accounts of episodic memory.

### **2.2. Context in Memory Models**

Computational models of episodic memory, striving for both explanatory power and psychological plausibility, have increasingly sought to incorporate the pervasive influence of context, reflecting its acknowledged importance in empirical research.9 However, the specific mechanisms by which context is represented, how it changes over time, and how it is utilized during encoding and retrieval vary considerably across different modeling frameworks. This section reviews how several prominent models—including the Temporal Context Model (TCM), Retrieving Effectively from Memory (REM) and its variants (with a detailed focus on the model described in 3), the Search of Associative Memory (SAM) model, and the Bind Cue Decide Model of Episodic Memory (BCDMEM)—approach the complex challenge of modeling context.

To provide a structured overview and facilitate comparison, Table 2.2.A summarizes key aspects of these influential models concerning their treatment of contextual information. This table highlights their primary mechanisms for context representation, how context influences retrieval processes within each model, their key strengths in modeling contextual phenomena, and some of the inherent limitations or challenges they face, particularly when dealing with dynamic or complex contextual scenarios.

**Table 2.2.A: Comparative Overview of Contextual Memory Models**

|Model Name|Primary Mechanism for Context Representation|How Context Influences Retrieval|Key Strengths for Modeling Context|Key Limitations/Challenges for Modeling Dynamic or Complex Context|
|---|---|---|---|---|
|**TCM (Temporal Context Model)**|Dynamically evolving temporal context vector, influenced by item presentations; context represented as a distributed pattern of features that drifts gradually over time. 10|Current temporal context acts as a retrieval cue; overlap between current context and an item's encoding context determines activation. Recalled items can reinstate their encoding context, influencing subsequent retrieval (retrieved context mechanism). 11|Provides a strong, mechanistic account of temporal context effects, including recency and contiguity effects across various time scales; explicitly models item-driven context change. 11|Primarily focused on temporal aspects of context; less explicit about how other types of context (e.g., spatial, semantic, internal state) are integrated, unless they can be mapped onto the temporal drift mechanism. May require extensions to handle abrupt, non-temporal context shifts.|
|**REM (Retrieving Effectively from Memory)**|Contextual features are stored as part of discrete, probabilistic episodic memory traces, alongside item-specific features. Each trace is an incomplete and potentially noisy copy of the event. 9|Context features of the probe (or current retrieval environment) are matched against context features in stored traces; this match contributes to the overall likelihood ratio used for old/new recognition decisions. 7|Highly flexible feature-based representational framework that can, in principle, incorporate diverse types of contextual information; probabilistic encoding accounts for variability in memory strength and context encoding. 7|Original versions of REM were less focused on the continuous, dynamic drift of context within an episode or across multiple episodes, and lacked explicit mechanisms for context updating or reinstatement without specific extensions.|
|REM Variant (3)||Explicit distinction between Changing Context (CC_ℓ) features (25, `δ_list`=0.14 change between lists) and Unchanging Context (UC) features (25, stable across lists), alongside Content (C) features (25). 3|Two-step decision: 1. Context Filtering (CC & UC match against probe, threshold `τ`=100). 2. Content Feature Evaluation (criterion `Θ_j` decreases 1 to 0.6). Context features contribute to filtering and overall match. 3|Specifically models dynamic contextual changes (inter-list `δ_list`, intra-list `δ_drift`=0.14, post-test `δ_reinstate`=0.4); distinguishes stable vs. labile context; models context-sensitive decision criteria and final test emphasis on UC. 3|Increased complexity due to numerous parameters governing context dynamics; requires strong empirical grounding and justification for specific parameter values and dynamic rules (e.g., rate of CC change, differential use of UC/CC across test phases 3).|
|**SAM (Search of Associative Memory)**|Context often represented as a global context vector that is combined with item cues to form the overall retrieval probe. 9|Context forms an integral part of the retrieval cue; the match between the cue (including context) and memory traces influences the sampling probability of traces in a global matching process. Recovered items can also update the context. 14|Accounts for a broad range of free and cued recall phenomena; the global matching concept has been highly influential. Can model effects of overall contextual similarity.|Original versions often represent context in a less specific, less feature-rich manner compared to models like REM; dynamic context change within an episode or fine-grained contextual drift is not a primary focus without extensions.|
|**BCDMEM (Bind Cue Decide Model of Episodic Memory)**|Episodic memory trace for an item consists _only_ of contextual information (often binary features) present during encoding; the item itself acts as a pointer to this learned context vector. 9|Recognition based on the match between the reinstated study context and the retrieved item-specific context trace; decision often based on a likelihood ratio. Context noise (ambiguity of item-context bindings) is a primary source of interference. 16|Strong focus on context noise as a source of interference; provides a clear mechanism for predicting a null list-length effect for item recognition. 17|The assumption that item features are not stored in the episodic trace is a strong and debated one; binary context features may limit the richness of context representation. Modeling highly dynamic or multifaceted contexts can be challenging.|

#### **2.2.1. Temporal Context Model (TCM)**

The Temporal Context Model (TCM), developed by Michael Howard, Marc Kahana, and their colleagues, stands as a significant theoretical framework specifically designed to provide a detailed and mechanistic account of how temporal context influences episodic memory, with a particular emphasis on explaining phenomena observed in free recall tasks, such as recency and contiguity effects.10 At its conceptual core, TCM represents context not as a static backdrop but as a dynamically evolving vector of features – a representation of the cognitive state that changes gradually over time.10 This contextual representation is not merely passively drifting; it is actively and continuously updated by the presentation and processing of items themselves.11 When an item is studied, it becomes associated with the specific state of this temporal context vector prevailing at that precise moment of encoding.During retrieval, the current state of the temporal context vector acts as a primary retrieval cue.11 Items that were previously studied are activated, and thus become available for recall, to the extent that their original encoding context (i.e., the state of the context vector when they were initially studied) overlaps or matches with the current contextual cue.11 This fundamental mechanism naturally and elegantly accounts for recency effects – the superior recall of items from the end of a list – because these recently studied items were encoded in a temporal context that is highly similar, if not identical, to the temporal context present at the immediate time of test.11A key and innovative feature of TCM is the concept of "retrieved context".11 This principle posits that when an item is successfully recalled, it does not only bring the item itself to conscious awareness but also partially reinstates the temporal context in which that item was originally encoded.11 This reinstated context then serves as an updated cue that influences the retrieval of subsequent items. This retrieved context mechanism provides a powerful and parsimonious explanation for temporal contiguity effects – the robust empirical finding that items studied close together in time tend to be recalled successively in clusters.11 Because the reinstated context of a just-recalled item is, by definition, more similar to the encoding contexts of its temporal neighbors (both forward and backward in the study list) than to more distant items, these neighboring items are more likely to be cued and recalled next. This process can iterate, with each recalled item reinstating its context and cueing the next, leading to the characteristic associative chaining observed in free recall.The item-driven nature of context change is a significant and distinguishing aspect of TCM.11 Unlike some models where context might be treated as an entirely external signal that changes independently of item processing (e.g., purely due to the passage of time), TCM posits that the very act of perceiving and processing an item contributes to the evolution of the temporal context vector.11 This has profound implications for understanding how the specific sequence and identity of experienced items actively shape the subjective temporal landscape of memory. It suggests that our internal sense of time in memory is not just a passive clock but is actively constructed by the flow of experience.While TCM offers a robust and mathematically specified framework primarily for temporal context, the question of how its mechanisms relate to other forms of context or to parameters in other models, such as the `δ_drift` parameter in the 3 model (which represents the probability of context features drifting between study and test 3), is an area for further consideration and potential integration. The `δ_drift` in 3 could be conceptualized as a more general form of contextual change that might encompass temporal drift but also other, non-temporal fluctuations. TCM's strength lies in its detailed account of how temporal relationships are encoded and used, making it a cornerstone for understanding the temporal organization of episodic memory. However, extending its principles to fully account for the rich variety of non-temporal contextual influences (e.g., spatial, semantic, emotional contexts) remains an ongoing area of development, often requiring assumptions about how these other contextual dimensions might be mapped onto or interact with the primary temporal context vector.

#### **2.2.2. Retrieving Effectively from Memory (REM) and its variants**

The Retrieving Effectively from Memory (REM) model, first introduced by Richard Shiffrin and Mark Steyvers in 1997, is a highly influential probabilistic model primarily focused on explaining recognition memory, though its principles have been extended to other memory phenomena.9 REM has been successful in accounting for a variety of benchmark findings in the recognition literature.7 A central assumption of the REM model is that each encountered experience (e.g., a word presented in a study list, along with its encoding context) is stored in memory as a distinct, separate episodic image or trace.7 Each of these memory traces is conceptualized as a vector of feature values, where these features represent the different perceptual, semantic, and contextual aspects of the studied item and the circumstances of its encoding.7A critical aspect of REM is that the encoding process is assumed to be probabilistic and inherently error-prone.7 This means that each stored memory image is typically an incomplete and potentially noisy or distorted copy of the actual event as it was experienced. Not all features of an event may be successfully stored in its trace, and the values of those features that are stored might not perfectly match the original values. This probabilistic encoding mechanism provides a natural way to account for variations in memory strength and the common observation that memories are often imperfect.During a recognition test, when a probe item is presented to the system, its features are systematically compared to the features stored in all the existing memory traces. The model then typically calculates a likelihood ratio.7 This ratio quantifies the probability of observing the degree of match between the probe item's features and the stored features in the memory traces if the probe item were indeed "old" (i.e., previously studied and corresponding to one of the stored traces) versus the probability of observing that degree of match if the probe item were "new" (i.e., not previously studied and thus matching the stored traces only by chance). This likelihood ratio, or a related probability derived from it, forms the quantitative basis for the recognition decision (e.g., if the likelihood ratio exceeds a certain criterion, an "old" response is made).7

Contextual information can be naturally and seamlessly incorporated into the REM framework by including a set of contextual features alongside item-specific features within each memory trace vector. This allows the model to account for context effects in recognition memory, as the degree of match between the contextual features of the probe (or the contextual features of the current retrieval environment) and the contextual features stored in a particular memory trace will contribute to the overall likelihood ratio for that trace. If the retrieval context closely matches the stored encoding context of an old item, the likelihood ratio for that item's trace will be higher, increasing the probability of a correct "old" judgment.

REM has been successfully applied to explain a range of phenomena, including the list-strength effect (or often, the null list-strength effect in recognition), where the model's assumptions about how item repetitions are stored (often by strengthening the features within a single trace rather than creating multiple new, identical traces) play a crucial role.18 Various extensions and variants of the REM model have been developed over the years to broaden its explanatory scope and to address new empirical findings or different aspects of memory. For example, D-REM (Dynamically Retrieving Effectively from Memory) was developed to incorporate a dynamic decision-making mechanism, allowing it to predict not only accuracy but also response times in recognition tasks, which the original REM model did not explicitly address.19 Other variants, such as REM.3, have focused on specific empirical effects like spacing effects, often by elaborating on how repetitions are encoded under different temporal conditions.18The specific REM-based model detailed in the provided document 3 serves as a sophisticated and contemporary example of a REM variant specifically tailored to investigate the role of dynamic and multifaceted context in recognition memory. Its key components and parameters relevant to context processing are particularly noteworthy:

- **Context Representation:** The model 3 defines a total of 75 features per memory trace. These are meticulously divided into three distinct categories: 25 content features (C), which are intrinsically tied to the studied items themselves (e.g., perceptual or semantic features of a picture); 25 changing context features (CC_ℓ), which represent dynamic aspects of the context that are prone to vary between different study lists (ℓ denotes the list number); and 25 unchanging context features (UC), which represent more stable, enduring aspects of the experimental context or the participant's internal state that are assumed to remain constant across all lists.3 This explicit tripartite division of features allows for a nuanced representation of both stable and fluctuating contextual influences.
- **Context Dynamics and Change Mechanisms:** The model 3 incorporates several mechanisms to simulate the dynamic nature of context:
    - **Inter-List Context Change:** Each of the 25 changing context features (CC_ℓ) has a probability, denoted by `δ_list` = 0.14, of changing its value from one study list to the next.3 This parameter directly models the contextual shifts that occur between distinct learning episodes.
    - **Intra-List Context Drift:** Within a single list, context is also assumed to be dynamic. There is a probability of contextual drift, `δ_drift` = 0.14, for _both_ changing context (CC) and unchanging context (UC) features between the moment an item is studied and the moment it is subsequently tested within that same list.3 This captures the gradual evolution or degradation of contextual information over shorter retention intervals.
    - **Context Reinstatement:** After each test trial within a list, there is a probability of context reinstatement, `δ_reinstate` = 0.4, where features that had drifted from their study state are restored to their original study values.3 The documentation notes that this reinstatement probability results in approximately 92% of features being reinstated to their study values after 5 lists, suggesting a cumulative effect where the active context tends to be nudged back towards the original study context over repeated trials, albeit imperfectly on any single trial.3
- **Feature Encoding and Storage Probability:** The encoding of features into memory traces is probabilistic, governed by distinct geometric base rates for context features (`g_context` = 0.3) and word/item content features (`g_word` = 0.4).3 A specific storage probability for context, denoted `U_star`, varies depending on the list number and whether it is the first test item in a list, indicating that context encoding strength might differ under certain specific conditions (e.g., higher for the very first item of the first list, `U_star` = 0.1, versus `U_star` = 0.04 for later lists 3). A general copying parameter `c` = 0.8 also influences the fidelity of feature storage across all trials.3
- **Memory Update During Testing (Restorage):** A crucial aspect of the model 3 is the assumption that the testing phase is not merely a passive retrieval period but also involves active memory modification or "restorage."
    - For items judged as "old" (targets), the model assumes that the existing trace corresponding to the maximum likelihood match is retrieved, and its _content features_ (C) are strengthened. Specifically, blank (zero-valued) or mismatched content features in the trace have a probability of being restored to match the probe's features. Notably, context features (CC and UC) are _not_ strengthened in this process.3
    - For items judged as "new" (which includes foils), a new memory trace is formed and stored. The probe's content and context features undergo the same probabilistic storage process as items encountered during the initial study phase.3 The model also specifies differential storage for targets versus foils during testing if a target is re-encountered: "Perfect storage of target: Item that is tested as target is assumed to be stored better than foils (prob storage 1 for target and 0.04 for foil, probability copying 1 for target and 0.8 for foil)".3 This implies that correctly identified targets might receive a significant encoding boost upon re-presentation at test.
- **Decision Process:** Recognition decisions in the model 3 involve a sophisticated two-step sequential evaluation process:
    1. **Context Filtering:** First, the context features (both CC_ℓ and UC) of the stored memory traces are compared to the corresponding context features of the probe item (or the current retrieval context). Likelihoods based on this contextual match are computed. Traces whose contextual match falls below a specified context threshold, `τ` (tau) = 100, are effectively filtered out or significantly down-weighted in the subsequent decision stage.3 This acts as an initial screening based on contextual plausibility.
    2. **Content Feature Evaluation:** For those memory traces that pass the context filtering stage (or are sufficiently weighted), the content features (C) are then evaluated. Likelihoods based on the match of content features are calculated and compared against a decision criterion, `Θ_j` (Theta_j).3 This criterion is itself dynamic within a list, decreasing linearly from an initial value of 1 down to 0.6 across the 20 test positions (j: 1 to 20) within that list.3 This means the criterion becomes more lenient as the test progresses.
- **Final Test Phase:** The model 3 includes a distinct final test phase designed to assess long-term memory retention and the role of more stable contextual information.
    - In this final test, the criterion for content feature evaluation (`Θ_j`) is set to a stricter, constant value of 1, indicating a more conservative threshold for recognition decisions.3
    - A key aspect of this phase is the composition of the contextual probe: it emphasizes unchanging context, comprising 90% unchanging context (UC) features and only 10% changing context (CC) features.3 This reflects an assumption that long-term memory retrieval may rely more on stable, overarching contextual cues rather than recent, transient ones.
    - Even during this final test, a slow contextual drift is modeled for the changing context component. There is a small probability, `p_f` = 0.02, that each feature of the final test's CC component changes, based on the order of items in the final test.3 This mirrors a very gradual decay or shift in dynamic memory features over extended periods.
    - The context probe for the final test is also specified to be "a little different from the end list in initial test," 3 suggesting a slight shift from the context prevailing at the very end of the initial learning and testing sequence.

The 3 model's explicit distinction between Changing Context (CC_ℓ) and Unchanging Context (UC) features is a particularly notable refinement within the broader REM framework. This allows for the simultaneous modeling of relatively stable, long-term background contextual factors (represented by UC) and more transient, list-specific, or even item-induced contextual fluctuations (represented by CC_ℓ). This dual representation is crucial for understanding how memory operates in complex, real-world environments where some contextual elements persist across many experiences while others evolve rapidly. The model's prediction plots, as shown in 3, demonstrate its capacity to capture various patterns, including between-list effects (how performance changes from List 1 to List 10), within-list effects contingent on test position (e.g., serial position curves within a test block), and within-list effects contingent on study position (e.g., how well items are remembered based on where they appeared in the study sequence). This suggests its potential to account for a diverse range of context-related phenomena.The adaptive decision criterion (`Θ_j`) that decreases linearly across test positions in the initial testing phase of the 3 model is another sophisticated feature. This could reflect several underlying psychological processes, such as participant fatigue as the test progresses, evolving expectations about the likelihood of encountering a target versus a foil, or a strategic response to the accumulation of output interference from previously tested items. The shift to a much stricter and fixed criterion (

`Θ_j` = 1) in the final test phase appropriately models a more conservative decision strategy that might be adopted when assessing long-term, durable memories, where only strong evidence of prior occurrence is accepted.

Furthermore, the initial "Context Filtering" step in the 3 model's decision process, which uses both CC and UC features to compare traces against a threshold `τ`, can be interpreted as a computational mechanism analogous to a recollection-like check. If an item's associated contextual information (as stored in its trace) does not sufficiently match the probe's context or the reinstated study context, the trace might be rejected early in the decision process or deemed significantly less likely to be old, even before a detailed analysis of its content features is undertaken. This aligns conceptually with dual-process theories where the successful recollection of specific contextual details provides strong, often definitive, evidence for a prior encounter. The REM variant in 3 thus represents a significant step towards a more nuanced and dynamic understanding of context within a feature-matching framework.

#### **2.2.3. Other relevant models (e.g., SAM, BCDMEM)**

Beyond the Temporal Context Model (TCM) and the Retrieving Effectively from Memory (REM) framework, other influential computational models have also made significant contributions to our understanding of how context interacts with episodic memory processes. Two particularly notable examples are the Search of Associative Memory (SAM) model and the Bind Cue Decide Model of Episodic Memory (BCDMEM).

The **Search of Associative Memory (SAM)** model, originally developed by Jeroen Raaijmakers and Richard Shiffrin in 1981, is a foundational global matching model that has had a profound impact on memory research, particularly in explaining phenomena in free and cued recall.9 In SAM, retrieval is initiated by a set of retrieval cues. These cues typically include information about the item being sought (if available, as in cued recall) and, crucially, information about the current context. This context is often represented as a global context vector, a set of features representing the overall environment or internal state at the time of retrieval.14 These combined cues are then compared in parallel against all memory traces stored in the system – a process known as global matching.14The activation of each memory image (trace) is determined by the strength of its association with the available cues (both item and context cues). Retrieval in SAM is typically conceptualized as a two-stage process 14:

1. **Sampling:** In the first stage, a single memory image is _sampled_ from the entire set of traces. The probability of a particular image being sampled is proportional to its activation level relative to the summed activation of all other images in memory. This is often implemented using a Luce choice rule.14 Thus, traces that are more strongly activated by the current cues (including context) are more likely to be sampled. This stage inherently involves episodic interference, as all matching memories compete to be sampled.14
2. **Recovery:** Once an image is sampled, the second stage involves an attempt to _recover_ the information contained within that image (e.g., the identity of the item). The success of recovery can also depend on the strength of the trace or the amount of information stored within it.14 If recovery is successful, the item is recalled. The recalled item itself can then become part of the cue set for subsequent retrieval attempts, potentially updating the context and guiding the search further.

Context plays a crucial role in SAM by guiding the search process, influencing which traces are most likely to be sampled due to their match with the contextual component of the retrieval cue.14 While SAM has been highly successful in explaining a wide array of recall phenomena (e.g., list-length effects in recall, effects of cue overload, part-list cuing inhibition), its representation of context has often been less detailed or feature-rich compared to models like REM, particularly concerning the fine-grained, dynamic changes in context that might occur within a single learning episode or across very short timescales. Original versions often employed a relatively undifferentiated global context vector.The **Bind Cue Decide Model of Episodic Memory (BCDMEM)**, proposed by Simon Dennis and Michael Humphreys in 2001, offers a distinct and somewhat radical "context-noise" perspective on recognition memory.9 A central and defining tenet of BCDMEM is that the episodic memory trace formed for an item consists _only_ of the contextual information that was present during its encoding; the item itself (e.g., the word) is conceptualized as acting merely as a pointer to this learned context vector.17 In a significant departure from many other models, BCDMEM assumes that item-specific features are _not_ newly encoded into the episodic trace during the experimental episode; rather, the pre-existing representation of the item becomes associated with the current context.17Context features in BCDMEM are often represented as binary values (e.g., 0 or 1, indicating the absence or presence of a feature).16 Learning, in this framework, involves the stabilization or "permanent storage" of some of these contextual feature values in the memory trace associated with the item.16 During a recognition test, when a probe item is presented, the current experimental context is assumed to be reinstated in memory. Simultaneously, the item cue activates and retrieves its associated context trace from memory.16 The recognition decision of whether the item is "old" or "new" is then based on the degree of match (or overlap) between this reinstated current context and the retrieved context trace associated with the item.16 This match is often evaluated using a likelihood ratio.A key prediction of BCDMEM, which stems directly from its context-noise assumption, is a null list-length effect for item recognition.17 According to BCDMEM, interference in recognition does not primarily arise from competition among multiple studied items (item noise). Instead, interference is primarily attributed to the difficulty of discriminating the target item's specific encoding context from other contexts that may have been associated with that same item from prior, non-experimental encounters (context noise).17 Because the decision for each item is based only on its own context trace compared to the current context, the number of other items studied in the list is considered irrelevant to this specific comparison.A fundamental distinction emerges when comparing these models, particularly REM/SAM versus BCDMEM, regarding the primary locus of interference or "noise" that limits memory performance. Models like REM and SAM tend to emphasize _item noise_ (or trace interference), where interference arises from the presence of many similar items or traces in memory, making it difficult to isolate the correct target trace or accurately assess its strength relative to others.17 In contrast, BCDMEM emphasizes _context noise_, where interference arises from the difficulty in uniquely identifying or matching the specific context in which the target item was encountered, especially if the item itself is familiar and has been experienced in multiple different contexts previously.17 This theoretical divergence has significant implications for predicting various memory phenomena, most notably the list-length effect in recognition, where item-noise models generally predict at least some decrement in performance with longer lists, while pure context-noise models like BCDMEM may predict no such effect.17Furthermore, these models vary considerably in the specificity and dynamism of their context representations. Early versions of SAM often employed a relatively global, undifferentiated context vector. TCM, by contrast, focuses intensely on a dynamically evolving temporal context vector, where change is gradual and often item-driven.11 REM and BCDMEM utilize more specific, item-associated sets of context features, though BCDMEM's features are often binary and the trace contains _only_ context.16 The REM variant detailed in 3 takes the specificity of context representation further by distinguishing between Changing Context (CC_ℓ) and Unchanging Context (UC) features, each with its own parameters for updating and its own distinct role in the decision process.3 This represents a significant move towards more structured, functionally differentiated, and dynamically evolving contextual representations within computational models of episodic memory, aiming to capture the multifaceted ways context shapes our recollections.

### **2.3. Empirical Findings on Context Effects**

A vast and continually growing body of empirical research has unequivocally demonstrated the profound and remarkably varied ways in which context influences episodic memory. These findings span diverse experimental paradigms, types of contextual manipulations, and memory measures, collectively providing critical benchmarks that any comprehensive theory or computational model of memory must be able to address and explain. This section reviews several key empirical phenomena related to context effects, highlighting their characteristics and theoretical implications.

#### **2.3.1. List length effects**

The list length effect in recognition memory refers to the observation that, under certain conditions, memory performance (e.g., accuracy in discriminating old from new items) can be poorer for items that were studied as part of longer lists compared to items studied in shorter lists.21 This phenomenon has been a focal point in the theoretical debate between different classes of memory models.The effect is generally predicted by models that emphasize **item noise** or **trace interference**, such as many variants of the REM model.17 These models typically assume that increasing the number of items studied (and thus the number of memory traces stored) leads to a more crowded memory space. This increased "clutter" elevates the potential for interference among similar traces, making it more difficult to correctly identify target items as "old" and to correctly reject foils as "new".17 Essentially, as more items are stored, the probability of a foil spuriously matching features of one or more stored traces increases, potentially inflating the false alarm rate, and the unique signal from a target trace might be harder to discern against a noisier background, potentially decreasing the hit rate.Conversely, models that primarily attribute interference to **context noise**, such as the BCDMEM, often predict a null list-length effect in item recognition.17 In BCDMEM, for example, the recognition decision for a given item is based on the match between the reinstated study context and the specific context trace associated with that item alone.17 Since this comparison does not directly involve other items from the study list, the number of other studied items is, in principle, irrelevant to the decision for the current item. Interference in BCDMEM arises more from the pre-experimental history of an item (i.e., if it has been encountered in many different contexts before the experiment) rather than from other items within the current experimental list.The empirical status and interpretation of the list length effect in recognition have been subjects of considerable debate and research. Some studies have reported robust list length effects, while others have found them to be small or even absent, particularly when potential confounding factors are carefully controlled.20 Such confounds can include differences in total study time per item (shorter lists might allow for more processing per item if total study time is fixed), differential rehearsal strategies, or attentional factors.20 When these are equated, the magnitude of the list length effect often diminishes. For instance, if participants are given proportionally more study time per item in longer lists to equate total encoding opportunity, the effect might be reduced.The modeling explorations documented in the provided materials 3 touch upon this complexity. The author of the reflections in 3 notes a relatively small drop in overall performance (probability correct, p(c)) from 0.82 to 0.80 as the number of studied items (and thus stored traces) increases from list 1 (average ~32 traces) to list 2 (average ~72 traces). This observed drop of 0.02 is described as "rather small," leading to the suggestion that "the storage of new traces (mostly from new foil tests) as an important factor at play during the initial lists" might not be a primary driver of performance changes, especially for explaining large shifts in confusing foil correct rejection rates.3 This implies that while the 3 model, being REM-based, would generally be expected to predict some degree of list length effect due to the accumulation of traces, the empirically observed magnitude of this effect in certain datasets might be minimal and require careful consideration of other contributing factors or model parameters. The performance across the 10 lists simulated by the 3 model (as shown in its "between list prediction" plot 3) inherently involves an increasing number of memory traces from previous lists, so its ability to capture the empirically observed magnitude (or lack thereof) of list length effects under various conditions serves as a relevant test of the model's assumptions about interference and trace accumulation. The challenge lies in quantitatively matching the model's predicted list length effect to empirical data, which can vary depending on the specific experimental design.

#### **2.3.2. Serial position effects (primacy, recency)**

Serial position effects are among the most robust and consistently observed phenomena in the study of human memory, particularly in tasks involving the recall or recognition of sequentially presented items.22 When individuals are presented with a list of items (e.g., words, numbers, pictures) and are later asked to remember them, their performance typically follows a characteristic U-shaped curve: items presented at the beginning of the list (the **primacy effect**) and items presented at the end of the list (the **recency effect**) are remembered significantly better than items presented in the middle of the list (the asymptote).22The **primacy effect** refers to the superior recall or recognition of the initial items in a sequence. This advantage is often attributed to the greater opportunity for rehearsal and more elaborate encoding of these early-list items.23 When the first few items are presented, participants have more attentional resources available and fewer preceding items to interfere with their processing. This allows for more extensive rehearsal, which is thought to facilitate the transfer of these items from a temporary short-term memory store into a more durable long-term memory representation.23 Factors that reduce the opportunity for rehearsal, such as rapid presentation rates or concurrent distracting tasks, tend to diminish the primacy effect.The **recency effect** refers to the superior recall or recognition of the final items in a sequence.23 The traditional explanation for the recency effect, particularly in immediate free recall, is that these last few items are still residing in a readily accessible short-term memory buffer or working memory at the time of test.23 Because they were encountered most recently, they have not yet been displaced by subsequent information and can be "read out" with high accuracy. This explanation is supported by findings that a brief period of interpolated activity (e.g., counting backwards for 30 seconds) between the end of the list presentation and the recall test often eliminates or significantly reduces the recency effect (as it displaces items from the short-term buffer), while typically leaving the primacy effect intact.However, alternative explanations for recency effects also exist, particularly for recency observed over longer time scales (long-term recency) or in recognition memory. One prominent alternative, central to models like the Temporal Context Model (TCM), is that recency arises due to the distinctiveness of the temporal context associated with recent items.11 According to this view, the temporal context at the time of retrieval is most similar to the temporal context in which the most recent items were encoded. This high degree of contextual overlap serves as a powerful retrieval cue, leading to enhanced memory for these items.11 This type of explanation can account for recency effects even when a short-term buffer account is less plausible (e.g., in continuous recognition tasks or after filled delays).The specific REM-based model described in 3, with its mechanisms for context drift (`δ_drift` = 0.14 between study and test for both CC and UC features) and context reinstatement (`δ_reinstate` = 0.4 after each test trial) 3, should, in principle, be capable of capturing recency effects. The drift mechanism implies that the context associated with an item will gradually change between study and test, making more recent items (with less drift) potentially more matchable. The reinstatement mechanism, by bringing the active context closer to the study context, could also differentially benefit items based on their original encoding context. The model's within-list prediction plots, particularly the one showing performance by study position 3, are designed to demonstrate these serial position phenomena. The author's reflections in 3 offer a specific hypothesis within this modeling framework: "For final testing, then use of mostly UC and some CC would produce recency." This suggests that immediate recency effects (e.g., within an initial test list) might be driven by the current state of the more labile changing context (CC_ℓ) features, while longer-term recency effects (e.g., in a final, delayed test where UC features are emphasized 3) might be supported by the superior retrieval of the stable unchanging context (UC) that was associated with the end-of-list items. Murdock (1962) also proposed that the shape of the serial position curve could be influenced by proactive and retroactive inhibition effects occurring within the list itself.23

Understanding and modeling both primacy and recency effects are crucial for any comprehensive theory of memory, as they reflect fundamental constraints on how information is encoded, maintained, and retrieved over time and in sequence.

#### **2.3.3. Output interference**

Output interference is a well-documented phenomenon in episodic memory research that describes the decline in memory performance, typically recall accuracy, as more items are retrieved during a memory test.24 In other words, the act of successfully retrieving some items from memory appears to impair the ability to subsequently retrieve other, not-yet-recalled items from the same study list or encoding episode.25 This usually manifests as a decrease in the probability of correctly recalling items tested later in a sequence and an increase in omission errors (failures to respond) as the test progresses.24 For instance, in a cued recall task where participants are given cues for multiple studied items one after another, their accuracy is often higher for the items cued early in the test compared to those cued later.

Several distinct but potentially complementary mechanisms have been proposed to explain the occurrence of output interference:

1. **Retrieval-Induced Forgetting/Strengthening Imbalance:** One possibility is that successfully retrieved items become strengthened in memory or more accessible due to the act of retrieval itself. This strengthening of recalled items might then, through competitive retrieval mechanisms, block or overshadow weaker, yet-to-be-recalled items, making them harder to access. This is related to the broader concept of retrieval-induced forgetting, where retrieving some information can lead to the forgetting of related, non-retrieved information.
    
2. **Cue Contamination or Alteration:** The retrieval process itself might contaminate or alter the effectiveness of the retrieval cues used for subsequent items.25 For example, if recalling an item involves reinstating its context, this reinstated context might then interfere with the use of slightly different contextual cues needed for other items. Alternatively, the act of searching memory might leave a "trace" that biases subsequent searches.
3. **Accumulation of Interference from Recalled Items:** As items are recalled, they might effectively become part of the current "mental context" or search set. If these recalled items share features with the remaining target items, they could generate interference, making it harder to discriminate and access the not-yet-recalled targets.
    
4. **Response Filtering and Inhibition of Recalled Items:** To avoid repeatedly recalling the same items, memory systems likely employ a response filter or an inhibitory mechanism that suppresses already-retrieved items.25 While adaptive for preventing perseveration, this filtering process might inadvertently make it more difficult to access related or similar items that have not yet been recalled, or the cognitive load of maintaining this filter might reduce resources available for further retrieval. Research suggests that a model accounting for output interference in cued recall needs both learning during retrieval and such a response filter.25
5. **Strategic Changes or Fatigue:** As a test progresses and participants experience increasing difficulty (due to accumulating interference), they might strategically change their retrieval approach, perhaps becoming more conservative or exerting less effort. General cognitive fatigue over the course of a lengthy test could also contribute to declining performance.
    

The specific REM-based model described in 3 incorporates features that could potentially contribute to or account for output interference. The "memory update during testing (restorage)" mechanism is particularly relevant.3 According to this mechanism, when an old item is judged (presumably correctly as "old"), its content features in the corresponding trace are strengthened. When a new item (foil) is judged (presumably as "new"), a new trace is formed and stored in memory.3 Both of these processes—strengthening of target traces and addition of new foil traces—could inadvertently increase the pool of competing traces or the overall "noise" in memory as the test progresses. This increased memorial "clutter" might make it progressively harder to access the remaining target items that are tested later in a list.Furthermore, the model's dynamic content feature evaluation criterion (`Θ_j`), which decreases linearly from 1 to 0.6 across the 20 test positions within a list 3, might function as an adaptive mechanism to counteract this build-up of output interference. By becoming more lenient in what is accepted as "old" later in the test, the model (and perhaps the participant it simulates) might be attempting to maintain a certain level of performance despite increasing retrieval difficulty. Alternatively, this decreasing criterion could reflect a strategic shift by participants as they experience increasing difficulty or changing expectations. The within-list prediction by test position generated by the 3 model (shown in its prediction plots 3) should ideally reflect a decline in performance if the model successfully captures output interference effects, or at least show how the changing criterion interacts with accumulating interference. The interplay between trace strengthening, new trace formation, and the adaptive criterion is key to how this model might address output interference.

#### **2.3.4. Context change and reinstatement**

The principle of context-dependent memory, a cornerstone of memory research, is empirically demonstrated by a wealth of findings showing that memory performance is significantly affected by the relationship between the context present during encoding (learning) and the context present during retrieval (testing).26 Specifically, **changing the context** between study and test typically impairs memory performance (e.g., lower recall or recognition accuracy), whereas **reinstating the original study context** at the time of retrieval enhances memory performance.26 This phenomenon is remarkably robust and has been observed across a diverse array of contextual manipulations and memory tasks.

The types of context that can elicit these effects are varied and include:

- **External Environmental Context:** This refers to the physical surroundings in which learning and retrieval occur. Classic examples include changing the room where participants study and are tested, altering background music or noise conditions 26, modifying visual cues like background colors or images 31, or even more dramatic changes like learning material on land versus underwater, as in the seminal study by Godden and Baddeley (1975).26 In Godden and Baddeley's experiment, scuba divers who learned lists of words underwater recalled them better when tested underwater, and those who learned on land recalled better when tested on land, compared to conditions where the learning and testing environments were mismatched.26
- **Internal State Context:** This encompasses the physiological and psychological state of the individual during encoding and retrieval. Examples include mood-dependent memory (better recall if mood at retrieval matches mood at encoding) 32, state-dependent memory related to drug or alcohol effects (information learned under the influence of a substance is often better recalled when in that same substance-induced state) 32, or even physiological states like arousal level or heart rate.31
- **Mental Context:** This refers to the internal cognitive environment, including the thoughts, cognitive operations, or imaginative state of the participant. For instance, instructing participants to think about a specific past personal event or to imagine a particular environment between study and test can create a mental context shift that influences memory.26 Even the task itself or the instructions given can form part of the mental context.

These empirical findings provide direct and compelling evidence for the **encoding specificity principle**, famously articulated by Tulving and Thomson (1973).26 This principle states that the likelihood of retrieving a memory is maximized when the cues available at retrieval match the cues that were processed and stored along with the target information during the initial encoding phase.33 Context, in its various forms, serves as a powerful and often pervasive set of such cues. It is not merely a passive backdrop but becomes intricately woven into the memory trace itself.27The effectiveness of context reinstatement is not limited to physical reinstatement. **Mental reinstatement**, where individuals are explicitly asked to vividly imagine and mentally reconstruct the original learning environment or their internal state during encoding, can also be a surprisingly effective technique for improving recall, particularly in situations where physical reinstatement is impractical (e.g., in eyewitness testimony, where witnesses might be asked to mentally return to the scene of the crime).30Computational models of memory must be able to simulate these fundamental effects of context change and reinstatement. The specific REM-based model described in 3, for example, explicitly incorporates parameters designed to address these dynamics. The parameter `δ_list` = 0.14, which governs the probability of changing context (CC_ℓ) features changing between lists 3, allows the model to simulate the impact of a significant contextual shift occurring between different learning episodes. A larger

`δ_list` would correspond to a greater change in context, which should, according to the model's mechanisms, lead to poorer memory for items from previous lists if CC features are important for retrieval.

Furthermore, the parameter `δ_reinstate` = 0.4, representing the probability that a drifted context feature (either CC or UC) is reinstated to its study state after each test trial within a list 3, directly models the process of context recovery during retrieval. The documentation for 3 notes that this value of `δ_reinstate` leads to approximately 92% of features being reinstated to their study values after 5 lists. This suggests a cumulative, albeit probabilistic and partial, reinstatement process. Perfect context reinstatement is unlikely in most real-world situations, so this probabilistic approach is psychologically plausible. The degree to which a computational model can accurately capture the quantitative impact of various degrees of context change and the corresponding benefits of different levels of reinstatement is a key measure of its validity and explanatory power. Research has also shown that low-frequency or more distinctive contexts (e.g., "low-frequency locations") tend to yield a stronger context-dependent memory effect; memories encoded in such distinctive contexts benefit more from a match between encoding and retrieval contexts compared to memories encoded in highly familiar or common contexts.34 This suggests that the distinctiveness or novelty of a context can modulate its effectiveness as a retrieval cue, a factor that future models might need to incorporate more explicitly.

#### **2.3.5. The role of temporal information and context drift**

Episodic memories are inherently imbued with a temporal dimension; they are often tagged with information about "when" an event occurred, at least relative to other events in one's personal past.35 The temporal organization of memory is significantly influenced by the continuous, gradual change or "drift" of temporal context over time.10 As experiences unfold sequentially, the internal temporal context—a representation of the cognitive state as it evolves through time—is thought to change progressively. Consequently, items or events that are encoded further apart in time become associated with more dissimilar contextual representations compared to items encoded closer together in time.35

This contextual dissimilarity arising from temporal drift is believed to play a crucial role in several aspects of temporal memory:

1. **Temporal Discrimination:** The differing contextual signatures of events encoded at different times can aid in differentiating these events based on their temporal proximity. For example, the **temporal distance effect** refers to the common finding that it is easier to judge the relative order of two items if they occurred far apart in time than if they occurred close together.35 This can be explained if the contextual representations of temporally distant items are more distinct and less confusable than those of temporally adjacent items.
2. **Recency Effects:** As discussed earlier, the similarity of the current temporal context to the encoding context of very recent items is a key explanation for recency effects, particularly within the Temporal Context Model (TCM).11
3. **Contiguity Effects:** The gradual drift of context, coupled with mechanisms for context reinstatement upon item recall (as in TCM), also underlies the tendency for items studied in temporal proximity to be recalled together.11

Furthermore, the concept of **event boundaries** is critical in understanding temporal context and memory organization.35 Event boundaries are salient changes in the external or internal environment that are perceived by an individual as segmenting the continuous flow of experience into discrete, meaningful events (e.g., entering a new room, a shift in topic of conversation, the start of a new task). Research suggests that these event boundaries can have a profound impact on the temporal context signal. Instead of just continuing to drift gradually, the temporal context may effectively be "reset" or significantly altered at an event boundary.35 This resetting mechanism is not necessarily a random shift but may involve the reinstatement of a proportion of initial contextual information, linking the new event back to a broader experiential framework.35Such contextual resets at event boundaries are proposed to have a dual role in temporal order memory (TOM) 35:

- They can **enhance** memory for the temporal order of items _within_ a single event. By creating a relatively distinct contextual segment for that event, the items within it are bound together more cohesively and are less subject to interference from items in other events.
    
- Conversely, they can **impair** memory for the temporal order of items _across_ different events. This is because the contextual link between the end of one event and the beginning of the next is disrupted by the reset, making it harder to bridge the temporal gap across the boundary.
    

The phenomenon of the **local primacy effect** also highlights the role of event boundaries and context drift, where items occurring closer to the beginning of a segmented event are better remembered in terms of their temporal order, even when absolute list positions are controlled.35 This is explained by the idea that the relative change in context is greater for earlier items within an event segment following a boundary reset.35The specific REM-based model described in 3 explicitly incorporates a mechanism for context drift via the `δ_drift` parameter. This parameter, set at 0.14, represents the probability that each context feature (both the changing CC_ℓ features and the unchanging UC features) changes its value between the study of an item and its subsequent test within the same list.3 This drift serves a dual function within the model:

1. It contributes to **forgetting** over even short retention intervals, as the retrieval context (which has drifted from the study context) becomes progressively more dissimilar from the original encoding context, reducing the match and thus the likelihood of successful recognition.
    
2. Simultaneously, it provides a basis for **temporal discrimination** (albeit implicitly), as items encoded at different points within a study list will be associated with differentially drifted contextual states by the time they are tested. While not as explicit as TCM's temporal vector, this feature-based drift can capture some aspects of temporal distinctiveness.
    

Computational models of episodic memory must capture these complex dynamics of temporal information and contextual drift to provide a comprehensive account of how the crucial "when" aspect of our experiences is encoded, organized, and retrieved. The interplay between gradual drift and more abrupt, event-driven contextual shifts remains an active area of research and modeling.

### **2.4. Recognition Memory Paradigms**

The empirical investigation of recognition memory, and the manifold contextual influences upon it, relies on a variety of well-established experimental paradigms. These paradigms differ in terms of what specific aspect of memory they primarily probe (e.g., memory for individual items versus memory for associations), how they structure the study and test phases, and the types of responses and performance measures they elicit. Understanding these paradigms is crucial for interpreting experimental findings and for designing computational models that can simulate the observed behaviors.

#### **2.4.1. Item recognition**

Item recognition is arguably the most fundamental and widely used paradigm for studying recognition memory.19 In a typical item recognition task, the experimental procedure involves two main phases:

1. **Study Phase (Encoding):** Participants are presented with a list of items to study. These items can vary widely depending on the research question and can include words, pictures, faces, sounds, or other types of stimuli.36 Participants are usually instructed to try to remember these items for a later memory test. The presentation can be sequential, and factors like presentation duration, inter-stimulus interval, and list length can be manipulated.
2. **Test Phase (Retrieval):** After a retention interval (which can range from seconds to days, and may or may not include an interpolated distractor task to prevent rehearsal 19), participants are presented with a series of test items. Some of these test items were part of the original study list (these are referred to as **targets** or **old items**). Other test items were not on the study list (these are referred to as **foils**, **lures**, or **new items**).19 For each test item presented, the participant's task is to make a judgment, typically a binary "old" or "new" decision (a yes/no recognition test), indicating whether they believe they encountered that specific item during the preceding study phase.37 Alternatively, in a forced-choice recognition test, participants might be presented with two or more items (e.g., one target and one or more foils) and asked to choose which one was studied.37

Performance in item recognition tasks is typically quantified using several key measures derived from Signal Detection Theory (SDT) 19:

- **Hit Rate (HR):** The proportion of target (old) items that are correctly identified as "old".19 (HR = Number of Hits / Total Number of Targets).
- **False Alarm Rate (FAR):** The proportion of foil (new) items that are incorrectly identified as "old".19 (FAR = Number of False Alarms / Total Number of Foils).
- **Derived SDT Measures:**
    
    - **d' (d-prime):** This is a measure of sensitivity or discriminability, reflecting the participant's ability to distinguish between old and new items, independent of their response bias.40 It represents the standardized difference between the means of the memory strength distributions for old and new items. A larger d' indicates better discriminability.40 The formula often used is d' = z(FAR) – z(HR) if using right-tail p-values, or d' = z(HR) - z(FAR) if using left-tail p-values for the z-scores.40 (Note: The formula in 40 is d' = z(FA) – z(H) where FA and H are right-tail probabilities, so z(H) would be negative for high H, making d' positive. If H and FA are proportions, then d' = Z(H) - Z(FA) where Z is the inverse of the standard normal CDF).
    - **c (criterion):** This is a measure of response bias, reflecting the participant's overall tendency to respond "old" or "new," regardless of their actual memory accuracy. A negative value of c indicates a liberal bias (tendency to say "old"), a positive value indicates a conservative bias (tendency to say "new"), and a value around zero indicates no bias.
        

Although item recognition tasks focus on memory for individual items, they are nonetheless influenced by context. The overall context of the study list (e.g., its semantic theme, the modality of presentation, the physical environment) can affect how items are encoded and subsequently recognized. Environmental context effects, such as better recognition performance if participants are tested in the same room where they studied, have been demonstrated in item recognition paradigms. The specific REM-based model described in 3 is primarily designed as an item recognition model. It simulates the old/new decision process for individual stimuli based on a comparison of their stored content features (C) and associated context features (CC_ℓ and UC) against those of a probe item, ultimately yielding a decision based on the `Θ_j` criterion after context filtering with `τ`.3 The model's predictions for hit rates and correct rejection rates (1-FAR) for targets and foils across different lists and positions 3 are direct outputs relevant to item recognition performance.

#### **2.4.2. Associative recognition**

Associative recognition paradigms are specifically designed to assess memory for the relationships or associations _between_ items, rather than memory for individual items in isolation.36 These tasks probe a more complex aspect of episodic memory, requiring participants to remember not just

_what_ they encountered, but also _what was paired with what_.

In a typical associative recognition task:

1. **Study Phase (Encoding):** Participants are presented with pairs of items to study (e.g., word-word pairs like A-B, C-D; picture-word pairs; face-name pairs). They are instructed to learn these specific pairings.
    
2. **Test Phase (Retrieval):** During the test phase, participants are presented with a series of item pairs. Their task is to judge whether each presented pair is "intact" or "recombined."
    
    - **Intact pairs:** These are pairs that were studied together in that exact combination during the study phase (e.g., A-B).
        
    - **Recombined pairs (or rearranged pairs):** These pairs consist of two items that were both presented during the study phase, but they were originally part of _different_ pairs (e.g., if A-B and C-D were studied, a recombined pair might be A-D or C-B). Sometimes, pairs containing one studied item and one entirely new item, or two entirely new items, are also included as foils, depending on the specific research question.
        

Successful performance on associative recognition tasks requires more than just recognizing that the individual items within a test pair are familiar. Participants must retrieve specific information about their joint occurrence or the particular association formed between them during the study episode.38 For example, if presented with the recombined pair A-D, a participant might recognize both A and D as being familiar from the study list, but to correctly reject the pair as "recombined," they must fail to retrieve (or correctly retrieve the absence of) a specific memory of A and D having been presented

_together_.

Context is often considered to play an even more critical role in associative recognition than in item recognition. The shared encoding context of an item pair (i.e., the specific temporal, spatial, and internal context in which items A and B were encountered together) is thought to be a crucial cue for judging that pair as intact. When an intact pair is presented at test, the reinstatement of this shared encoding context can facilitate a correct "intact" judgment. Conversely, interference can arise if retrieving the individual items of a recombined pair (e.g., A and D) activates their separate, non-shared encoding contexts from the study phase. This might lead to an incorrect "intact" judgment if the individual item familiarity is high and the associative information is weak, or it might lead to uncertainty and slower response times.

Some theories suggest that associative recognition relies more heavily on recollection-based processes (which are rich in contextual detail) compared to item recognition, which can often be supported by familiarity alone. Remembering that two items were specifically paired requires retrieving that episodic link, a hallmark of recollection.

While the specific REM-based model described in 3 is primarily focused on item recognition, its underlying principles of context feature encoding and matching could potentially be extended to simulate associative recognition performance. This would likely require defining how context features are shared, bound, or uniquely configured when two items are presented as a pair during encoding. For instance, an associative trace might contain content features for both items plus a set of context features representing their joint encoding episode. A recombined pair would then mismatch this specific conjoint contextual representation, even if the individual item features were familiar. The challenge would lie in specifying how these associative traces are formed and how they are compared against intact versus recombined probes during the decision process. The distinction between item memory (retrieval of semantic features) and associative memory (connection between different semantic features) is highlighted in 41, emphasizing that different concepts underlie different endpoints in memory connections.

#### **2.4.3. The influence of foil types**

The characteristics of the foil (lure or distractor) items used in a recognition memory test are not trivial details; they significantly influence performance and can provide invaluable insights into the nature of memory representations, the types of information encoded, and the retrieval processes participants employ.42 Foils are not a monolithic category; they can be strategically designed to vary in their relationship to the studied target items, thereby probing different aspects of memory. Understanding how different foil types affect hit rates and, more critically, false alarm rates, is essential for building and testing comprehensive memory models.

Common types of foils include:

- **Entirely New Foils (Unrelated Foils):** These are items that have no prior experimental history within the current study and bear no specific pre-planned relationship (e.g., semantic, perceptual) to any of the items presented on the study list. False alarm rates to these types of foils serve as a baseline measure of the tendency to make false positive errors when no specific relationship exists between the target and the foil.

- **Related Foils (Similar Foils):** These are foils that are intentionally designed to bear some form of similarity to one or more of the studied target items. This similarity can manifest in several ways:
    
    - **Semantic Similarity:** Foils might be synonyms (e.g., if "boat" was studied, "ship" might be a foil), category associates (e.g., if "apple" was studied, "pear" or "fruit" might be foils), or thematically related items. High false alarm rates to semantically related foils can indicate that participants are relying on gist-based memory (i.e., remembering the general meaning or theme rather than specific item details) or that their memory representations are imprecise, leading to confusion between items with similar meanings.
        
    - **Perceptual Similarity:** Foils might be visually similar to studied pictures (e.g., a picture of a slightly different red car if a specific red car was studied), or auditorily similar (e.g., words that sound alike but have different meanings). High false alarm rates here suggest that perceptual features are being encoded but perhaps not with enough detail to distinguish between similar exemplars.
        
    - Phonological Similarity: For verbal stimuli, foils might be homophones (e.g., "their" if "there" was studied) or rhyming words. These probe the specificity of phonological encoding.
        
        The pattern of false alarms to these different types of related foils can provide crucial diagnostic information about the nature of the features encoded into memory traces and the level of detail at which they are represented.
        
- **Source Memory Foils (or Context Foils):** These are particularly interesting foils, often used in source memory or context memory paradigms. These foils are items that _were_ actually studied by the participant, but they were encountered in a different source or context than the one currently being probed. For example, if participants study List 1 in Room A and List 2 in Room B, during a test for List 2 items, an item from List 1 could be presented as a source memory foil. To correctly reject such a foil (i.e., to say it wasn't from List 2, even though it's familiar), the participant must not only recognize the item as old but also correctly retrieve its original source or context (List 1, Room A) and determine that it mismatches the current target context (List 2, Room B). High false alarm rates to source memory foils indicate difficulties in binding items to their specific encoding contexts or in retrieving that binding.
    
- **Strong vs. Weak List Foils (Strength-Based Mirror Effect):** As discussed by Criss and colleagues, and a topic of considerable theoretical interest, the encoding strength of the target list itself can influence false alarm rates to objectively identical new foils.1 Typically, in what is known as the **strength-based mirror effect (SBME)**, false alarm rates (FARs) are _lower_ for foils tested after a strongly encoded list (e.g., items studied for longer durations or repeated multiple times) compared to foils tested after a weakly encoded list.1 This is counterintuitive for some simpler models because the foils themselves are identical and have no direct connection to the encoding strength manipulation of the targets. Two main theoretical explanations have been proposed for the SBME's effect on foils 1:
    1. **Criterion Shift Assumption:** This metacognitive explanation posits that participants become aware (either during encoding or through initial test trials) that their memory for a strong list is generally very good. Consequently, they adopt a stricter, more conservative decision criterion for judging items as "old." This stricter criterion leads to fewer "old" responses overall, thus reducing false alarms to new foils, even though the underlying memory strength of the foils themselves is assumed to be unaffected by the list strength manipulation.1
    2. **Differentiation Models:** In contrast, differentiation models propose that the memory representations themselves are altered by strong encoding. Stronger encoding of target items leads to more precise, detailed, and distinctive memory traces. These highly differentiated target traces are then less confusable with _any_ foil item. According to this view, the distribution of subjective memory strength for foils actually _decreases_ (becomes less "old-like") when tested in the context of a strongly encoded list compared to a weakly encoded list, because the well-defined target memories provide a clearer contrast.1 Evidence from response time distributions analyzed within the diffusion model framework, and some fMRI studies, has been interpreted as supporting differentiation accounts by suggesting that strong-list foils elicit higher quality evidence for "newness" (e.g., faster accumulation of evidence towards a "new" response).1

The modeling explorations documented in the provided materials 2 highlight the particular importance and challenge of explaining performance for what are termed "confusing foils" (CFs). The author of the reflections in 2 grapples with how to account for changes in correct rejection (CR) rates for these CFs across multiple study lists (e.g., an observed rise in CRs for CFs as lists continue). The 2 model includes specific parameters for how foils are processed during the "memory update during testing (restorage)" phase (e.g., `prob storage 0.04 for foil`, `prob copying 0.8 for foil` 2), indicating that the model explicitly accounts for the encoding of foil encounters. The pattern of false alarms (or correct rejections) to different types of foils, especially confusing ones that might share contextual or content features with targets, serves as a critical diagnostic tool. It reveals the nature of the information being stored in memory traces and the retrieval strategies (including decision criteria and context matching rules) employed by participants. For instance, if CRs for confusing foils increase across lists, as pondered in 2, it suggests that participants are becoming better at rejecting these specific lures. This improvement could be due to several factors within a model like 2: better learning of target contexts (making the foils stand out as contextually inappropriate), changes in retrieval strategy (e.g., more stringent context filtering via the `τ` parameter 2), dynamic changes in how different types of context features (CC vs. UC) are utilized, or changes in the magnitude of context change between lists (`δ_list` 2), as speculated in the modeling reflections.2Furthermore, it is crucial to recognize that the test phase of a recognition experiment is not solely a period of retrieval; it is also an **encoding episode** in itself. New foil items encountered during a recognition test can be incidentally encoded into memory, and the strength of this incidental encoding can be influenced by the cognitive operations engaged during the test (e.g., whether the retrieval task encourages deep semantic processing or shallower, non-semantic processing of the test items).3 This phenomenon is captured by the 2 model's "Memory Update During Testing (Restorage)" mechanism, which explicitly posits that a new trace is formed when a new item (foil) is judged (presumably as "new").2 This is particularly critical for multi-list experiments, as traces from foils presented and encoded during List 1 become part of the memorial background influencing performance on List 2 and all subsequent lists. Accurately modeling the acquisition and subsequent influence of these foil traces is thus a critical test for any comprehensive recognition memory model aiming to account for performance over extended experimental sessions. The interaction between the type of foil, the strength of target encoding, and the evolving contextual landscape of a multi-list experiment presents a rich set of phenomena for both empirical investigation and computational modeling.

### **2.5. Computational Modeling in Memory Research**

Computational modeling has emerged as an indispensable and powerful methodology for advancing the understanding of human memory, allowing researchers to translate often complex and verbally articulated theories into precise, explicit, and testable mathematical or algorithmic frameworks.4 This rigorous approach offers several distinct advantages for studying intricate cognitive processes such as the effects of dynamic context in episodic memory, processes that are often difficult to observe directly or isolate purely through behavioral experimentation.To facilitate a detailed understanding of the specific REM-based model 2 that forms a central part of this dissertation's modeling efforts, Table 2.5.A provides a comprehensive summary of its key parameters, particularly those related to the representation and processing of contextual information. This table is based on the detailed description provided in.2Table 2.5.A: Key Parameters of the Investigated REM-based Model 2

|Parameter Symbol|Description of Parameter|Value/Range as per 2|Role in Context Processing and Memory Dynamics|
|---|---|---|---|
|`CC_ℓ`|Changing Context features per list|25 features per trace|Represents dynamic, transient contextual elements that are prone to vary between distinct learning episodes (lists ℓ = 1-10). These features capture the fluctuating aspects of the encoding environment.|
|`UC`|Unchanging Context features|25 features per trace|Represents stable, enduring contextual elements that are assumed to persist across all study lists (e.g., the general experimental room, consistent internal states, overall task set).|
|`C`|Content features|25 features per trace|Represents the intrinsic perceptual or semantic features of the studied items (pictures in this case) themselves, distinct from context.|
|`δ_list` (Delta_list)|Probability each CC feature changes its value between lists|0.14|Governs the rate of contextual shift or alteration specifically for the changing context (CC_ℓ) features from one study list to the next. A higher value implies more contextual change between episodes.|
|`δ_drift` (Delta_drift)|Probability each context feature (both CC_ℓ and UC) drifts between study and test within a single list|0.14|Models the gradual change, fluctuation, or degradation of contextual information over shorter time scales, such as the retention interval between an item's presentation and its subsequent test within the same list.|
|`δ_reinstate` (Delta_reinstate)|Probability a drifted context feature (CC_ℓ or UC) is reinstated to its original study state after each test trial|0.4|Models the partial recovery or refreshing of the original encoding context during or after retrieval attempts within a list. This is a cumulative process, with ~92% of features reinstated after 5 lists.|
|`g_context`|Geometric base rate for storing context features (CC_ℓ and UC) during encoding|0.3|Influences the overall probability that any given contextual feature present during an encoding event is successfully stored into the corresponding memory trace. Lower values mean sparser context encoding.|
|`g_word`|Geometric base rate for storing content features (C) during encoding|0.4|Influences the overall probability that any given content feature of an item is successfully stored into its memory trace.|
|`U_star`|Special probability of storage for context features (varies by list number and test position)|List 1 study: 0.08; Subsequent lists study (except 1st test): 0.04; List 1, 1st test item: 0.1; Subsequent lists, 1st test item: 0.08|Modulates the strength of context encoding at specific critical points in the experiment, suggesting, for example, that context might be encoded more robustly at the very beginning of the experiment or the start of a new test block.|
|`c` (Copying parameter)|Probability that a feature value from the environment is correctly copied into the memory trace if storage occurs|0.8|Influences the fidelity of feature storage across all lists, study trials, and test trials for both content and context features. A value less than 1 implies imperfect copying.|
|`τ` (Tau)|Context filtering threshold in the decision process|100|Determines how well a stored trace's context features (both CC_ℓ and UC) must match the probe's context (or the current retrieval context) to pass the initial filtering stage of the recognition decision. Traces below this match threshold are effectively excluded or down-weighted.|
|`Θ_j` (Theta_j)|Content feature evaluation criterion (for initial test lists, decreases across test positions `j`)|Linearly decreases from 1 (for test position j=1) to 0.6 (for test position j=20)|Sets the threshold for the content feature match required for an "old" judgment during the initial test lists. The decreasing nature suggests an adapting or more lenient criterion as the test progresses.|
|`Θ_j` (Final Test)|Content feature evaluation criterion in the final test phase|1 (constant)|Sets a stricter, more conservative threshold for "old" judgments in the final long-term retention test, requiring stronger content evidence.|
|`p_f`|Probability each CC feature of the _final test's context probe_ changes based on final test item order|0.02|Models very slow contextual drift or fluctuation specifically within the changing context component of the retrieval probe during the extended final test phase.|
|Context Probe (Final Test)|Composition of context features used for probing memory in the final test|90% Unchanging Context (UC) features, 10% Changing Context (CC_ℓ) features|Reflects an assumption that long-term memory retrieval in the final test phase relies more heavily on stable, enduring contextual cues (UC) rather than recent, transient ones (CC_ℓ). The probe is also "a little different from the end list in initial test."|
|Restorage (Targets)|Memory update for judged-old targets during testing|Content features (C) only are strengthened (blank/mismatched features restored to match probe). Context features (CC_ℓ, UC) are NOT strengthened.|Models learning during retrieval, where successful recognition reinforces the item's content representation.|
|Restorage (Foils/New)|Memory update for judged-new items (foils) during testing|A new trace is formed for the foil. Its content (C) and context (CC_ℓ, UC) features undergo the same probabilistic storage process as items during initial study.|Models the incidental encoding of new information encountered during the test phase.|
|Restorage (Targets vs. Foils at test)|Differential storage if a target is re-tested vs. a foil being tested|"Perfect storage of target: Item that is tested as target is assumed to be stored better than foils (prob storage 1 for target and 0.04 for foil, probability copying 1 for target and 0.8 for foil)" 2|Suggests a significant encoding advantage for re-encountered targets during the test phase compared to the initial encoding of foils.|

#### **2.5.1. Advantages and approaches**

One of the foremost advantages of employing computational modeling in cognitive psychology, and particularly in memory research, is that it compels researchers to be exceptionally **explicit and precise** about their theoretical assumptions and the proposed mechanisms underlying cognitive functions.4 Verbal theories, while often rich in conceptual insight, can sometimes harbor ambiguities, underspecified processes, or hidden assumptions. The rigorous process of translating these verbal theories into a working computational model—whether as a set of mathematical equations, a computer algorithm, or a simulated neural network—forces these ambiguities to be confronted and resolved. All necessary components of the theory, their representations, and their interactions must be clearly defined and implemented.4 This inherent demand for precision can lead to deeper theoretical insights, the unmasking of previously unacknowledged complexities or internal contradictions within a theory, and the identification of critical gaps that require further empirical or theoretical work.8 The reflective and iterative process documented in the modeling notes 2, where a researcher systematically grapples with justifying different modeling choices for context dynamics (e.g., "how are large and increasing changes in CC justified?" or "is it reasonable that no UC is used for the initial lists?"), perfectly illustrates this heuristic value of modeling. It is not merely a tool for theory testing, but a powerful engine for theory development and refinement.Computational models also provide an unparalleled ability to **simulate complex cognitive processes** and to systematically explore how various interacting factors influence behavior in ways that are often difficult, impractical, or ethically impossible to achieve through human experimentation alone.4 Researchers can manipulate model parameters—which might represent, for example, the strength of encoding, the rate of forgetting, the speed of contextual drift, the sensitivity of a decision criterion, or the connectivity between neural units—and observe the direct consequences for simulated memory performance (e.g., hit rates, false alarm rates, response times, recall probabilities).4 This allows for the testing of specific hypotheses about underlying mechanisms in a highly controlled and transparent virtual environment. For instance, one can simulate the effects of varying levels of contextual overlap between study and test far more precisely than can typically be achieved in a behavioral study.Furthermore, well-constructed computational models can **generate novel, precise, and often counterintuitive predictions** about behavior in new situations or under different experimental conditions.4 These predictions can then be empirically tested with human participants to validate or falsify the model and, by extension, the theory it embodies. This iterative interplay between computational modeling and empirical research—where models guide experiments and experimental results constrain and refine models—is a hallmark of robust scientific progress in cognitive science and cognitive neuroscience.7Various broad approaches to computational modeling exist within cognitive science, each with its own strengths and philosophical underpinnings 6:

- **Symbolic Models (or Information-Processing Models):** These models represent knowledge and cognitive processes using symbols (e.g., propositions, schemas, rules) and explicit rules for manipulating these symbols (e.g., production systems). They often focus on higher-level cognitive architecture and algorithmic descriptions of processes. Many classic memory models, including early versions of SAM, have strong symbolic components.
    
- **Connectionist Models (or Parallel Distributed Processing (PDP) Models / Neural Networks):** These models are inspired by the structure and functioning of the brain. They consist of interconnected networks of simple processing units ("neurons") that communicate via weighted connections. Learning in these models typically occurs through the gradual adjustment of these connection weights based on experience (e.g., via algorithms like backpropagation). Connectionist models are particularly adept at pattern recognition, generalization, and capturing the distributed nature of representations.6
- **Hybrid Models:** These models attempt to combine the strengths of both symbolic and connectionist approaches, for example, by using connectionist networks to implement lower-level perceptual or associative processes, which then feed into higher-level symbolic reasoning systems.6
- **Mathematical/Probabilistic Models:** This category includes models like REM 9 and BCDMEM 10, which use probability theory and statistical principles to define representations and decision processes. They often focus on deriving quantitative predictions for behavioral data like accuracy and response distributions. The REM model, for instance, uses probabilistic feature encoding and likelihood ratio calculations for recognition decisions.9

The choice of modeling approach often depends on the level of explanation sought by the researcher (e.g., a cognitive-level algorithm versus a more neurally plausible implementation), the specific phenomena being modeled, and the type of data available for model fitting and testing. Regardless of the specific approach, the overarching goal is to create a formal, computable instantiation of a theory that can deepen our understanding of the mechanisms of memory.

#### **2.5.2. Previous modeling of context effects using REM**

The Retrieving Effectively from Memory (REM) model, with its core assumption of feature-based representations stored in discrete episodic traces, provides a natural and flexible framework for incorporating and investigating the influence of contextual information on memory processes.9 In the REM framework, contextual features can be treated analogously to item-specific features: they are encoded (probabilistically and potentially imperfectly) as part of the memory trace for an event, and they contribute to the overall match calculation when a probe item is compared against stored memories during a recognition test.9 This means that the similarity between the context associated with a test probe (or the current retrieval environment) and the context stored in a memory trace directly influences the likelihood that the trace will be deemed a match, and thus affects the probability of an "old" judgment.

REM and its various extensions have been employed to account for a range of memory phenomena where context is thought to play a significant, albeit sometimes implicit, role. For example:

- **List-Strength Effects:** REM has been notably successful in explaining the often-observed null list-strength effect in recognition (where strengthening some items on a list does not impair recognition of other, weaker items on the same list), or sometimes slightly positive list-strength effects under specific conditions.12 The model's assumptions about how item repetitions and study time affect trace strength (often by updating features within a single trace rather than creating multiple new traces for repetitions, a concept known as differentiation 12) are critical to these predictions. Contextual similarity between repetitions can influence whether they are integrated into a single trace or stored separately.
- **Spacing Effects:** The spacing effect refers to the robust finding that memory is generally better for items whose presentations are spaced apart in time rather than massed (presented consecutively). Modified REM frameworks have addressed spacing effects, often by incorporating assumptions about how the perceived or encoded context changes over different temporal lags.12 If spaced repetitions are encoded with more distinct contextual features due to greater contextual drift between presentations, their traces might be more discriminable or less subject to interference, leading to better memory. Shiffrin and Steyvers (1997) discussed the possibility that repetitions might be represented in a single trace only if the subject identifies the item as having been previously studied, which is more plausible for massed than spaced items; incorporating this allows REM to predict spacing effects.12
- **Mirror Effect:** The mirror effect describes the phenomenon where factors that increase the hit rate for a class of items also decrease the false alarm rate for foils of that same class (e.g., high-frequency words have lower hit rates and higher false alarm rates than low-frequency words). REM can account for aspects of the mirror effect through its feature-matching and likelihood ratio mechanisms.9

The specific REM-based model detailed in the provided documentation 2 represents a particularly sophisticated and targeted application of REM principles to the explicit modeling of **dynamic context effects**. Its architecture and parameterization (summarized in Table 2.5.A) are designed to capture how contextual representations evolve over multiple timescales and across different learning and testing experiences. Several key features of this model 2 highlight its advanced approach to context:

1. **Explicit Distinction between Changing Context (CC_ℓ) and Unchanging Context (UC) Features:** This is a crucial innovation. By defining separate sets of context features—CC_ℓ features that can change between lists (with probability `δ_list`=0.14) and UC features that remain stable across all lists—the model can simultaneously represent and investigate the influence of both transient, episode-specific contextual elements and more enduring, global background contextual factors.2 This distinction is vital for understanding memory in complex environments where some aspects of context fluctuate while others persist. The modeling reflections in 2 extensively explore the potential differential roles and justifications for these two types of context.
2. **Modeling of Multi-List Dynamics and Contextual Evolution:** The model 2 is explicitly designed to operate over multiple study-test lists (10 lists in the described simulation). It incorporates parameters that govern:
    - **Inter-list context change (`δ_list`):** How CC_ℓ features evolve from one list to the next.
        
    - **Intra-list context drift (`δ_drift`):** How both CC_ℓ and UC features change between an item's study and its test within the same list.
        
    - Context reinstatement (δ_reinstate): The probabilistic restoration of drifted context features to their study state after each test trial.
        
        These mechanisms allow the model to simulate how contextual representations are not static but are continuously updated, degraded, and refreshed throughout an extended experimental session. This is critical for understanding cumulative learning, proactive and retroactive interference effects mediated by contextual similarity, and the long-term trajectory of memory performance.
        
3. **Context-Sensitive Decision Process:** The recognition decision in the 2 model involves a two-step sequential process where context plays a primary role in the initial stage:
    - **Context Filtering:** Stored traces are first compared to the probe based on their CC_ℓ and UC features. Traces whose contextual match falls below a threshold (`τ`=100) are effectively filtered out or down-weighted.2 This can be seen as an initial plausibility check based on context, akin to a recollection attempt for contextual information.
    - **Content Feature Evaluation:** Only traces that pass this contextual filter are then subjected to a more detailed evaluation of their content features (C) against a decision criterion (`Θ_j`).2 This architecture explicitly hypothesizes that contextual match is not just one component of an overall similarity score but can act as an early gate or a strong modulator of whether an item is even considered for content-based recognition. The dynamic nature of `Θ_j` (decreasing from 1 to 0.6 across test positions in initial lists) further suggests an adaptation to changing retrieval conditions or interference levels within a list.2
4. **Dedicated Final Test Phase with Emphasis on Stable Context:** The inclusion of a distinct final test phase in the 2 model is a significant feature for probing long-term contextual memory. In this phase:
    - The decision criterion (`Θ_j`) is set to a stricter, constant value of 1.2
    - Crucially, the contextual probe used for retrieval heavily emphasizes unchanging context features (90% UC and 10% CC_ℓ).2
    - A very slow drift is applied to the CC_ℓ component of the final test probe (`p_f`=0.02).2 This phase is designed to assess the retention and retrieval of more stable, long-term contextual representations, and to explore how memory performance might shift when reliance on recent, fluctuating contextual cues (CC_ℓ) is reduced in favor of more enduring ones (UC). This directly addresses some of the conceptual questions raised in the modeling reflections 2 about the differential roles of UC and CC in initial versus final testing and the potential for UC to be stored but not utilized until a later, more demanding retrieval scenario.

These features, taken together, position the 2 model as a powerful computational tool for investigating how a REM-based system can account for the complex, dynamic, and multifaceted interplay of stable and fluctuating contextual factors in recognition memory across various timescales and experimental conditions. It moves beyond simpler notions of context as a static set of features, embracing its evolving nature and its integral role in shaping memory encoding, storage, and retrieval decisions. The prediction plots included with the 2 model description (showing between-list performance, within-list performance by test position, and within-list performance by study position, as well as final test predictions) illustrate its capacity to generate detailed, quantitative predictions that can be compared against empirical data, thereby testing the plausibility of its architectural and parametric assumptions regarding context.

### **2.6. Gaps in the Literature and Rationale for Current Studies**

The preceding comprehensive review of theories of episodic memory, the pivotal role of context, established empirical findings, and various computational modeling approaches has illuminated a vibrant and intricate field of research. It underscores the significant progress made in understanding how we remember past experiences and the environmental, temporal, and internal cues that shape these recollections. However, this extensive survey also brings into sharp focus several significant gaps in our current understanding and existing modeling capabilities. These gaps are particularly evident when considering the **dynamic nature of context**—how it changes over time, across experiences, and how these changes interact with the fundamental processes of recognition memory. Addressing these unresolved issues and limitations provides a compelling rationale for the specific research aims and objectives of this dissertation.

One major area that necessitates further intensive investigation is the **complex interplay between different types of dynamic context and more stable contextual representations.** While models like TCM excel at detailing the mechanisms of gradually drifting temporal context 16, and the REM variant outlined in 2 makes a significant contribution by incorporating mechanisms for both gradual intra-list drift (`δ_drift`) and more abrupt inter-list changes (`δ_list`), a more unified and comprehensive understanding of how these different timescales and types of contextual change are integrated by the human memory system is still lacking. The distinction in the 2 model between Changing Context (CC_ℓ) and Unchanging Context (UC) features is a promising and theoretically rich step in this direction. However, the precise rules governing their interaction, their relative contributions to memory performance across diverse paradigms (e.g., immediate versus delayed recognition tests, item versus associative recognition tasks), their potential differential susceptibility to interference, and their interaction with item-specific processing and strategic decision-making processes warrant more thorough empirical validation and computational exploration. The "final test" phase proposed in the 2 model, with its hypothesized shift in reliance towards UC features 2, points to a critically important but less commonly modeled aspect of memory: the transition from utilizing recent, labile contextual cues for immediate retrieval to relying on more stable, long-term contextual representations for durable memory access. How and why such a shift might occur, and what factors govern it, remain open questions.A significant and recurring challenge, explicitly and thoughtfully articulated in the modeling reflections 2, pertains to the **empirical and theoretical justification for specific assumptions made within computational models of context dynamics.** Questions such as "how are large and increasing changes in CC justified?" or "is it reasonable that no UC is used for the initial lists?" 2 highlight a crucial gap that often exists between a model's ability to fit a particular dataset (often through adjustment of multiple free parameters) and the conceptual plausibility or independent verifiability of its core architectural choices and parameter settings. While computational models provide invaluable precision, their explanatory power is maximized when their components map onto psychologically meaningful constructs and processes that have independent empirical support. This dissertation aims to directly address this gap by designing empirical studies that can systematically manipulate factors hypothesized to influence the dynamics of context (e.g., by varying the rate or predictability of environmental changes to influence `δ_list` or `δ_drift`, or by manipulating the salience of stable versus transient cues to affect the weighting of UC versus CC_ℓ). The data from these studies will then be used to constrain and test the computational model 2, assessing whether these manipulations produce the predicted effects on both overt behavior and the model's internal parameters. This approach seeks to move beyond potentially ad-hoc parameterization towards a more principled and empirically grounded understanding of the mechanisms underlying context-dependent memory.Furthermore, while many existing computational models of recognition memory, including REM and its 2 variant, can provide good accounts of accuracy data (i.e., hit rates and false alarm rates), a more complete and stringent test of their validity and generality involves their ability to **predict richer and more nuanced datasets.** This includes, for example, response times (RTs) for recognition decisions and confidence judgments associated with those decisions. Contextual manipulations often affect not just _whether_ an item is remembered, but also _how quickly_ and with _what degree of subjective certainty_ a recognition decision is made. For instance, a mismatch in context might slow down retrieval or reduce confidence even if accuracy remains relatively high. While the 2 model description focuses primarily on accuracy, and other REM variants like D-REM were specifically developed to address RTs in a REM framework 18, integrating such dynamic measures more broadly and systematically into models of context effects remains an important frontier. Extending the REM-based model developed and investigated herein to account for RT and confidence data could provide more stringent constraints on its assumptions about how context influences the rate of evidence accumulation, the placement of decision criteria, and the potential interplay of familiarity and recollection-like processes.The **influence of foil characteristics**, particularly the processing of "confusing foils" that share perceptual, semantic, or even contextual features with target items, also presents an ongoing challenge and an area ripe for further investigation.2 How varying contextual environments interact with different types of foil similarity to produce specific patterns of false alarms is not yet fully understood or comprehensively modeled. The dissertation's empirical work can systematically explore these interactions (e.g., by manipulating the degree of contextual overlap between study lists and then testing with foils that are either contextually congruent or incongruent with previous lists). The modeling component can then test specific mechanisms within the 2 framework (such as the context filtering stage `τ`, the role of `δ_list`, and the encoding of foil traces) that might account for the nuanced effects of different foil types under varying contextual conditions. The questions raised in 2 about explaining the rise in correct rejections for confusing foils across lists point directly to this complex interplay.

In summary, while existing theories and models have made significant strides in elucidating the role of context in episodic memory, there remains a pressing need for further research that:

1. Systematically investigates the dynamic interplay of different types of contextual information, including transient, rapidly changing cues (like CC_ℓ in 2) and stable, long-term background states (like UC in 2), and how these are integrated across multiple learning episodes and varying retention intervals.
2. Provides stronger empirical and theoretical justification for the specific mechanisms and parameter settings used in computational models of context, moving towards models whose components are not only mathematically tractable but also conceptually robust and independently verifiable.
    
3. Develops and refines computational models that can robustly integrate and predict the influence of both stable (long-term, global) and rapidly changing (short-term, local) contextual factors across diverse experimental paradigms (e.g., item vs. associative recognition, immediate vs. delayed tests) and over various time scales.
    
4. Explores the impact of context on a wider range of behavioral measures, including response times and confidence judgments, to more fully constrain theoretical models and provide a more comprehensive picture of context-dependent retrieval dynamics.
    
5. Addresses specific unresolved questions regarding context modeling, such as the differential utilization of changing versus unchanging context features during initial learning versus long-term retention tests, and the mechanisms underlying changes in performance for different types of foils across multiple learning episodes.2

The proposed empirical studies, outlined as the first principal objective of this dissertation (Aim 1.6.1), are meticulously designed to generate data that speak directly to these identified issues and gaps. The development, refinement, and rigorous testing of an extended REM-based computational model, using the sophisticated architecture described in 2 as a foundational starting point (the second principal objective, Aim 1.6.2), will provide a formal, quantitative framework for instantiating and evaluating specific hypotheses about these unresolved questions. By pursuing this synergistic approach—where empirical investigation informs theoretical modeling, and modeling, in turn, generates testable predictions that guide further empirical inquiry—this dissertation seeks to contribute to a more precise, mechanistic, and comprehensive understanding of the dynamic and multifaceted role of context in shaping human episodic memory.     