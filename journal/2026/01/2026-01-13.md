
## daily note
-  cog model [allDay:: true]


### 2. The Ontological View: Meaning through Dynamics

To make a purely internal function "ontologically identifiable," researchers rely on **Internal Dynamics** (how the function changes over time relative to itself), rather than external inputs.

- **Function $f_A$ (Habit/Exercise)**: You might define this function to be "Frequency-Dependent." Its only "input" is the agent's own previous output3333.
    
- **Function $f_B$ (Reward/Effect)**: You might define this function as "Outcome-Dependent"4.
    

Even if you hide the reward from the model, $f_A$ and $f_B$ are ontologically distinct because they have different **Update Logics**5555. One is an **Integrator** (it just adds up past actions), and the other is an **Evaluator** (it looks for changes). If the data shows "clumping" of behavior that ignores changes in the environment, the "Integrator" $(f_A)$ is the only one that can explain it6666.

### 3. Can you identify them without any Real-World Values?

Philosophically, if you remove **all** real-world inputs (no stimulus, no reward, no time), the model becomes a **closed loop**.

In the field, a model with no external "tethers" is generally considered **unidentifiable** in an ontological sense. You can define $f_A$ as "Habit" and $f_B$ as "Fatigue," but if they both just cause the agent to stop moving, there is no way to prove your definition is "true"7777. You are just ascribing meaning to a symbol ($A$) that has no causal connection to the world



|**Feature**|**Miller et al. (2019)**|**Gershman (2020)**|
|---|---|---|
|**Habit Term**|$\tau h(s, a)$ 11|$1 \cdot \log P^*(a)$ 121212|
|**Logic**|Habit is a "strength" built by doing. 13|Habit is a "frequency" that saves bits. 141414|
|**The "Weight"**|$\tau$ is an arbitrary number you "fit" to data. 15|The weight is **fixed at 1** by the math of information theory. 1616161616|
