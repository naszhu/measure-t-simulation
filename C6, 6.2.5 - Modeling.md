### 6.2.5 Modeling (SLR23 Model)

The primary objective of the modeling efforts described in Lai, Cao, and Shiffrin (2024) was to develop a comprehensive theoretical framework capable of elucidating the principal processes governing short- and long-term memory operations in the context of probe recognition tasks. The resulting model, termed SLR23 (Short-Term Memory, Long-Term Memory, Retrieval 2023), aimed not only to account for the new empirical findings presented in their paper but also to address and rectify certain conceptual and implementational shortcomings identified in a precursor model, SLR21 (Nosofsky et al., 2021). A critical benchmark for the success of SLR23 was its capacity to predict the intricate patterns observed in both accuracy and response time data across an extensive and diverse array of experimental conditions and participant groups, doing so with a coherent set of underlying mechanisms and a parameter set that remained largely consistent.

SLR23 is instantiated within the general architecture of the Exemplar-Based Random Walk (EBRW) model, a framework previously employed with considerable success in modeling categorization phenomena (e.g., Nosofsky & Palmeri, 1997). This choice reflects an orientation towards dynamic, evidence-accumulation perspectives on decision-making in memory. The notation adopted for SLR23 aligns with conventional mathematical psychology, primarily utilizing Greek letters to denote its parameters, aiming for clarity and consistency.

At its core, SLR23 posits that recognition decisions are driven by the interplay of two fundamental cognitive processes: **familiarity** and **learning**.

1. **Familiarity**: This process is conceptualized as a graded signal arising from the activation of memory traces. Crucially, SLR23 distinguishes between two loci of such traces:
    
    - **Short-term event traces**: These are episodic representations of items encountered within the current experimental trial (i.e., the current study list). Their activation is heavily influenced by factors such as recency.
        
    - Long-term event traces: These are episodic representations from prior trials. Their activation contributes to the overall sense of familiarity but can also be a source of interference, particularly in conditions like Varied Mapping (VM).
        
        The aggregate activation from these event traces, based on the similarity between the memory probe (the test item and its current context) and the stored traces, contributes to the evidence accumulation process. The probe itself is assumed not to contain response information, meaning that familiarity is independent of any response that might have been associated with a stored trace. This conceptualization of familiarity aligns with numerous models that use it to explain phenomena like list-length effects and various forms of interference (Lai, Cao, & Shiffrin, 2024).
        
2. **Learning**: This process refers to the acquisition and utilization of specific item-response associations. Within SLR23, learning is particularly relevant for Consistent Mapping (CM) conditions, where the stimulus-response mapping is stable across trials. A key theoretical commitment of SLR23 is that this learned information is stored and retrieved from **knowledge traces** (akin to semantic memory, as discussed in Nelson & Shiffrin, 2013), rather than being directly read out from individual event traces. This distinction is supported by empirical observations, such as those from Nosofsky, Cao, et al. (2014a), where performance on successive VM foil trials (where the item and correct response repeated) was harmed rather than helped, suggesting that the influence of the prior trial was mediated by a general familiarity/interference effect from the event trace, not by the retrieval of a specific (and in that case, helpful) response from that trace. In CM conditions, the retrieved information from a knowledge trace provides a more direct influence on the response decision (Lai, Cao, & Shiffrin, 2024).
    

SLR23 leaves open the possibility that responses might also be stored within individual event traces. However, because the memory probe in the model does not include response features, such stored responses would not influence the calculation of familiarity. The model effectively argues for the sufficiency of familiarity (derived from response-neutral event traces) and knowledge-based response retrieval to account for the observed recognition data, a stance supported by approaches like state-trace analysis (e.g., Dunn, 2008, as cited in Lai, Cao, & Shiffrin, 2024).

#### Implementation of SLR23 in the EBRW Framework

The conceptual ideas of familiarity and learning are translated into a formal mathematical structure within the EBRW framework. The decision process is modeled as a random walk, where evidence accumulates over discrete steps until it crosses one of two boundaries, representing an 'OLD' (target) or 'NEW' (foil) decision. The probability of taking a step towards a particular boundary on any given iteration is determined by the relative strength of evidence favoring that alternative.

The core equations governing the step probabilities are (Lai, Cao, & Shiffrin, 2024, p. 14):

$$
PTS​(T)=SkT​+2LT​+Λj​+ΦSkT​+LT​+Λj​​ (1a)
$$
$$

PTS​(F)=SkF​+2LF​+Λj​+ΦSkF​+LF​+Λj​​ (1b)
$$

Where:

- PTS​(T) is the probability of taking a step towards the 'OLD' boundary when a target is tested.
    
- PTS​(F) is the probability of taking a step towards the 'NEW' boundary when a foil is tested. (Note: The paper's equation (1b) describes PTS​(F) as the probability of a step toward the _foil_ decision boundary. The numerator for a foil test in a CM condition, if learning aids the correct 'NEW' response, should reflect evidence for 'NEW'. The paper's text states "in Eq. 2a [sic, likely means 1b] produces a tendency to step toward the foil boundary." If Λj​ represents learned evidence for the _correct_ response, then for a foil, it should contribute to a 'NEW' decision. The equations are structured such that Λj​ in the numerator pushes towards the target boundary in (1a) and, by its presence only in the denominator of an analogous equation for stepping towards the _target_ boundary when a foil is tested, it would push towards the foil boundary. The paper's equations are presented for stepping towards the _target_ boundary (PTS​(T)) and stepping towards the _foil_ boundary (PTS​(F)). For a foil test, Λj​ (strength of learned "NEW" response) in the numerator of PTS​(F) would indeed push towards the foil boundary. The paper's formulation is PTS​(F)=(SkF​+LF​+Λj​)/(SkF​+2LF​+Λj​+Φ). This implies Λj​ is the strength of the _correct learned response_. For a foil, the correct learned response is 'NEW'. Thus, Λj​ contributes to stepping towards the foil boundary. The paper's text (p.15) clarifies: "For target tests, Λj​ is in both the numerator and denominator [of PTS​(T) if LT​ is zero], so increases the step probability toward the correct target boundary. For foil tests, Λj​ is only in the denominator [of PTS​(T) for a foil, which is 1−PTS​(F)], so increases the step probability toward the correct foil boundary." This implies PTS​(F) should be written to reflect stepping towards foil. The equations as written in the paper (1a, 1b) are for PTS​(T) and PTS​(F) respectively, where PTS​(F) is the probability of stepping toward the _foil_ boundary. The term Λj​ is added to the numerator in both cases, implying it is evidence for the _tested item's specific learned response designation_. If item X is a CM target, Λj​ is evidence for "target". If item Y is a CM foil, Λj​ is evidence for "foil". This interpretation makes sense.)
    
- SkT​ and SkF​ represent the summed activation from short-term memory (STM) event traces when a target or a foil is tested, respectively, for a list of length k. Typically, SkT​>SkF​ because a target matches one of the STM traces perfectly. Both terms generally increase with list length k.
    
- LT​ and LF​ represent the summed activation from long-term memory (LTM) event traces (from prior trials) for targets and foils. In most conditions, LT​=LF​, except in standard CM paradigms (not the new one used in Lai, Cao, & Shiffrin, 2024) where targets are seen more often. These values depend on the experimental condition but not on the current trial's list length. They reflect activation from LTM traces that _match_ the current test item.
    
- The terms (SkT​+LT​) and (SkF​+LF​) collectively represent the **familiarity** component influencing the decision.
    
- Λj​ is the activation strength of the test item's **knowledge trace**, encoding the learned appropriate response for that item in the j-th CM condition. This is the **learning** component. Its value is allowed to vary across different types of CM conditions (e.g., pure CM vs. mixed CM) to reflect differing amounts of learning.
    
- Φ is a criterion parameter. It determines the baseline tendency to step in a particular direction. If the numerator equals Φ, the step probability is 0.5. It is held constant across all groups and conditions.
    
- The presence of LT​ (or LF​) in the numerator but 2LT​ (or 2LF​) in the denominator reflects the assumption that LTM event trace activation from prior trials is often non-diagnostic for the current decision and primarily adds variability (noise), thus pushing the step probability towards 0.5 as LTM activation increases.
    

Special cases of these equations apply for AN and VM conditions (Lai, Cao, & Shiffrin, 2024, p. 15):

For AN tests (no matching LTM traces, no learning):
$$
PTS​(T)=SkT​+ΦSkT​​ (2a)
$$
$$
PTS​(F)=SkF​+ΦSkF​​ (2b)
$$
Here, performance is driven by the difference in STM activation between targets and foils ($SkT​−SkF$​).

For VM tests (no learning, but LTM traces exist and LT​=LF​=L):
$$
PTS​(T)=SkT​+2L+ΦSkT​+L​ (3a)
$$
$$
PTS​(F)=SkF​+2L+ΦSkF​+L​ (3b)
$$
The L/2L component tends to make VM performance worse than AN performance due to the added noise from non-diagnostic LTM traces.

#### Short-Term Memory Dynamics: Recency and Trace Activation

A cornerstone of STM performance is the recency effect, where more recently studied items are better remembered. SLR23 captures this by assuming that the quality or strength (mh​) of an STM trace decreases as its lag h (position from the end of the study list, with lag 1 being the most recent) increases. This decay in trace quality is modeled by a power function with an asymptote (Lai, Cao, & Shiffrin, 2024, p. 15):

$$mh​=h−β+α (4)$$

where β is the rate of quality decrease, and α is the asymptotic quality at long lags.

The actual activation (aih​) of an STM trace at lag h by a test item i is the product of its quality mh​ and its similarity Ω to the probe:

aih​=mh​Ω (5)

The total STM activation for a given test probe, Sk​ (for a list of length k), is the sum of activations from all k traces in the current list:

Sk​=∑h=1k​aih​ (6)

#### Stages of Processing

Drawing inspiration from theories suggesting that perception and memory retrieval unfold in stages (e.g., Cox & Shiffrin, 2017; Harding et al., 2021, as cited in Lai, Cao, & Shiffrin, 2024), SLR23 implements a two-stage evidence accumulation process for familiarity calculation (illustrated in Lai, Cao, & Shiffrin, 2024, Fig. 4):

- **Stage 1**: This initial stage is brief, lasting for only one step of the random walk. It is assumed that during this stage, the memory probe consists primarily of low-level physical features of the test item. Consequently, only STM traces are activated, and the activation is similar for AN, VM, and CM items, differing mainly based on whether the probe matches an STM trace.
    
- **Stage 2**: This stage continues until a response boundary is reached. Higher-level, more abstract (e.g., semantic) features of the test item become part of the memory probe. During this stage, both STM and LTM event traces can be activated, and their combined influence, along with any input from knowledge traces (learning), drives the evidence accumulation.
    

#### Similarity Assumptions in Short-Term Activation

The similarity parameter Ω plays a crucial role in determining trace activation. SLR23 makes specific assumptions about how similarity differs for matching versus mismatching traces, and across processing stages and item types:

- **Matching Traces**: When the test probe matches an STM trace (i.e., the test item was the item stored in that trace), similarity is generally high. For Stage 2, the similarity of all STM matching traces (Ω2(match)​) is set to a single value, effectively setting the scale for activation. A different value, Ω1(match)​, applies for matching traces in Stage 1.
    
- **Mismatching Traces in Stage 1**: When the probe mismatches an STM trace in Stage 1, a specific similarity value, Ω1X(mismatch)​, is used.
    
- **Mismatching Traces in Stage 2 (**Ω2XX​**)**: A key assumption of SLR23 is that the similarity between a probe and a mismatching STM trace during Stage 2 can vary depending on the types of items involved (AN, VM, or CM). This is based on the idea that task demands and experience might lead to differential encoding of high-level features for these item types (Lai, Cao, & Shiffrin, 2024, p. 16, 19). Consequently, six distinct similarity values for mismatching STM traces in Stage 2 (Ω2XX​) were estimated, corresponding to the six possible pairings of probe type (AN, VM, CM) and trace type (AN, VM, CM) for mismatching items (e.g., VM-VM mismatch, AN-CM mismatch). These specific values, once estimated, were applied consistently across all studies and conditions whenever that particular type of probe-trace mismatch occurred. The values are detailed in Lai, Cao, and Shiffrin (2024, Table 2).
    

#### Long-Term Memory Dynamics: Context Change and Activation

LTM event traces from prior trials also contribute to familiarity. SLR23 assumes that only LTM traces that _match_ the current test item produce significant activation. The degree of this activation is influenced by the match between the current context (in the probe) and the context stored in the LTM trace. Since context is assumed to change or drift over trials, the activation from an LTM trace diminishes as the interval between its storage and the current test increases.

As a simplifying approximation, SLR23 calculates the total LTM activation based on the probability (P∗) that the current test item had a matching trace formed on the immediately preceding trial (either as a studied item or a tested item). This probability P∗ varies by experimental condition and group, as detailed in Lai, Cao, and Shiffrin (2024, Table 1). The total LTM activation for targets (LT​) and foils (LF​) is then proportional to these probabilities:

LT​=πPT∗​ (7a)

LF​=πPF∗​ (7b)

The parameter π controls the overall amount of LTM trace activation, effectively weighting the influence of LTM relative to STM. This parameter was held constant across all studies, groups, and conditions (Lai, Cao, & Shiffrin, 2024, p. 16).

#### Response Times and Response Boundaries

The random walk process continues until the accumulated evidence reaches either the 'OLD' decision boundary (ΘT​) or the 'NEW' decision boundary (ΘF​). These boundary values were fixed across all conditions. The predicted response time for a decision (RTRW​) resulting from this random walk process is given by (Lai, Cao, & Shiffrin, 2024, p. 18):

RTRW​=(Ns​)(χ)+τ0​ (8)

where Ns​ is the average number of steps required to reach a boundary (approximated using methods from Busemeyer, 1982, as cited in Lai, Cao, & Shiffrin, 2024), χ is the time (in milliseconds) taken for each step of the random walk, and τ0​ is a base time (or residual time). This base time accounts for perceptual encoding and motor response execution times not explicitly modeled by the random walk. The values of χ, ΘT​, and ΘF​ were fixed, while τ0​ was allowed to vary across the 13 distinct participant groups to capture baseline differences in processing speed.

#### Glitches

To account for occasional lapses of attention or non-model-based responses, SLR23 incorporates a 'glitch' mechanism (Lai, Cao, & Shiffrin, 2024, p. 18). It is assumed that on a small proportion of trials, participants make a random guess.

The probability of a glitch occurring is ξ, and when a glitch occurs, the response is random (0.5 probability correct) and takes a specific time τξ​. Both ξ and τξ​ were fixed across all groups and conditions.

The overall predicted probability of a correct response P(C) is:

P(C)=(ξ)(0.5)+(1−ξ)[p(c)] (9)

where p(c) is the probability of a correct response predicted by the main random walk process.

The overall predicted mean response time RT is:

RT=(ξ)(τξ​)+(1−ξ)RTRW​ (10)

#### Model Fitting Procedure

The parameters of SLR23 were estimated by minimizing a weighted discrepancy function that quantified the difference between the model's predictions and the observed data (accuracy and median correct response times) across all 376 unique data points from both the new studies and the relevant conditions from Nosofsky et al. (2021). The optimization was performed using the Julia programming language with the IPOPT solver via JuMP (Lai, Cao, & Shiffrin, 2024, p. 18).

The discrepancy for accuracy was the squared difference in probabilities, while for response time, it was the squared difference in seconds between the predicted mean time and the observed mean of median RTs across participants. Accuracy discrepancies were weighted twice as heavily as RT discrepancies, and foil data points were weighted four times more than target data points at individual lags (due to more observations contributing to foil means).

A key aspect of the fitting strategy was to maintain parsimony despite the complexity of the dataset. Of the model's parameters, most were held constant across all conditions and participant groups. The parameters allowed to vary were:

1. The learning rate (Λj​) for each of the eight distinct CM conditions (e.g., CM-Pure in Experiment 1, CM in MIX4 in Experiment 2, etc.).
    
2. The base response time (τ0​) for each of the 13 independent participant groups.
    
3. The six short-term mismatch similarity parameters (Ω2XX​), which depended on the specific types of AN, VM, or CM items involved in the probe-trace mismatch but were then applied consistently whenever that specific pairing occurred.
    
    The remaining 12 core parameters (e.g., Φ,ΘT​,ΘF​,χ,ξ,τξ​,π,α,β,Ω1(match)​,Ω1X(mismatch)​,Ω2(match)​) were fixed globally. This constrained approach was crucial for testing the generality of the model's core mechanisms.
    

#### Model's Account of Empirical Phenomena

The success of SLR23 is judged by its ability to capture the qualitative trends and patterns in the extensive dataset. Lai, Cao, and Shiffrin (2024) report that the model provides a good qualitative account, with predictions generally aligning well with observed data trends across the varied conditions (see Figs. 2 and 3 in their paper).

- **Recognition Above Chance**: The fundamental ability to discriminate targets from foils is captured by the higher STM activation for targets (SkT​) compared to foils (SkF​). This difference arises because a target perfectly matches one STM trace, leading to high similarity-based activation for that trace, whereas foils generally mismatch all STM traces. The parameters governing similarity for matching vs. mismatching items ensure this differential activation.
    
- **List Length Effects**: As list length (k) increases, the relative advantage of the single matching trace for a target is diluted by the increasing number of mismatching traces (k−1) that contribute to both SkT​ and SkF​. This dilution naturally leads to a decrease in performance (accuracy and RTs) with longer lists. The model's fixed criteria (Φ,ΘT​,ΘF​) and the way STM activation sums up result in the observed pattern where list length effects are prominent for foils, while target performance at a given lag is less affected by list length itself (though average target performance declines due to averaging over more long-lag items).
    
- **Learning and the CM Advantage**: The superiority of CM performance over VM and AN is directly attributed to the learning component, Λj​. In CM conditions, the consistent stimulus-response mapping allows for the formation of knowledge traces. Retrieval from these traces (contributing Λj​ to the step probability equations) biases the random walk towards the correct response boundary, supplementing the evidence from familiarity (S and L terms). The magnitude of Λj​ was estimated to be higher in conditions with more opportunity for learning (e.g., pure CM vs. mixed CM; standard CM vs. the new, more complex CM paradigm), aligning with theoretical expectations (Lai, Cao, & Shiffrin, 2024, p. 20-21).
    
- **CM versus VM versus AN Hierarchy**:
    
    - **CM > AN, VM**: As noted, learning (Λj​) elevates CM performance.
        
    - **AN > VM**: AN trials involve entirely new stimuli, so there are no matching LTM event traces (L=0). VM trials, however, use a recurring set of items. Thus, for VM items, LTM event traces from prior encounters are activated. Because these prior encounters are equally likely to have been targets or foils, this LTM activation (L) is non-diagnostic for the current decision. Its inclusion in the step probability equations (Eqs. 3a, 3b, particularly the L in the numerator and 2L in the denominator) effectively adds noise to the decision process, pushing the step probability towards 0.5 and thus degrading performance relative to AN conditions.
        
- **Target Lag (Recency) Effects**: The pronounced recency effect—better performance for more recently studied targets—is a direct consequence of the assumed decay in STM trace quality (mh​) with increasing lag h, as described by Equation 4 (mh​=h−β+α). The estimated value of β (approx. 1.70) produced lag functions that closely matched the steep declines observed in the data (Lai, Cao, & Shiffrin, 2024, p. 20).
    
- **Similarity Differences and Nuanced Condition Effects**: The assumption that STM mismatch similarity (Ω2XX​) in Stage 2 varies depending on the types of items (AN, VM, CM) being compared allows the model to capture more subtle differences in performance patterns across conditions where global parameters alone might fail. For instance, the specific nature of interference or discriminability between different types of stimuli (e.g., distinguishing a VM probe from other VM traces versus distinguishing it from CM traces in a mixed list) can be modulated by these type-specific similarity values. This was deemed a necessary complexity to achieve a good fit across the entire dataset (Lai, Cao, & Shiffrin, 2024, p. 19, 22).
    

In essence, SLR23 provides a proof by example that a set of core memory principles—staged processing, decaying STM traces, interfering LTM traces, distinct familiarity and learning mechanisms, and context/task-dependent similarity—can be integrated into a unified computational framework that successfully accounts for a wide spectrum of recognition memory phenomena. The model's ability to do so with a largely consistent set of parameters across numerous experimental manipulations lends considerable support to the validity of these underlying principles and their orchestrated operation in human memory.