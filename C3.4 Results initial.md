### **3.4. Results of Initial Study-Test Phase**

This section presents a comprehensive analysis of the behavioral data from the initial phase of Experiment 1, which comprised ten sequential study-test blocks. The goal is to characterize memory performance at multiple timescales: the global, between-list changes that occur as participants accumulate a large repository of episodic memories, and the local, within-list dynamics governed by an item's position in the study and test sequences. The analyses focus on the primary dependent measures of recognition accuracy—decomposed into Hit Rates (H) for previously studied targets and Correct Rejection (CR) rates for novel foils—and the associated response times (RTs) for correct judgments. The findings detailed herein serve as the foundational empirical patterns that the computational modeling efforts in Chapter 5 must explain.

Following the preprocessing steps outlined in the Data Analysis Strategy (Section 3.3), a total of [Number] participants were excluded for failing to complete the experiment or for not meeting the 60% final test accuracy criterion. The final analyses were conducted on a sample of [Number] participants (N=[Number] in the Forward condition, N=[Number] in the Backward condition, and N=[Number] in the Random condition). All statistical analyses of accuracy data were conducted using generalized linear mixed-effects models (GLMM) with a logit link function, predicting trial-level correctness. Analyses of log-transformed response times were conducted using linear mixed-effects models (LMM). All models included maximal random effects structures supported by the data, typically random intercepts for participants and items, to account for non-independence in the data.

---

#### **3.4.1. Between-List Effects: The Accumulation of Proactive Interference**

The multi-list design of the initial phase provides an ideal opportunity to investigate the consequences of accumulating episodic memories over time. A key question is how the encoding and retrieval of new information is affected by the presence of memories from prior lists. This build-up of interference from past learning, known as proactive interference (PI), is a cornerstone phenomenon in memory research. To assess its impact, we examined how recognition performance evolved across the ten main study-test blocks.

Figure 3.4.1 displays the mean Hit Rate for targets and the mean Correct Rejection rate for foils as a function of list number. A striking dissociation is immediately apparent in the data, a pattern that is closely matched by the model predictions shown in the provided materials. The performance on novel foils—pictures that were new to the experiment on every list —remains remarkably high and stable. As shown by the upper line in Figure 3.4.1, the Correct Rejection rate begins at approximately 0.92 in List 1 and fluctuates minimally across the subsequent nine lists, ending at a similar level. The tight confidence intervals surrounding this line underscore the consistency of this high performance both within and across participants. This stability demonstrates that participants’ ability to correctly identify and reject a picture they had never seen before was not degraded by the accumulation of nearly 200 other pictures in memory over the course of the session.

In stark contrast, the performance on target items, represented by the lower line in Figure 3.4.1, shows a marked and systematic decline across the lists. The Hit Rate begins at its peak in List 1, with an accuracy of approximately 0.92, nearly identical to the Correct Rejection rate for that list. This initial data point represents a relatively "pure" measure of recognition, as there is no proactive interference from prior experimental lists. However, a sharp deterioration in performance occurs immediately thereafter. From List 1 to List 2, the Hit Rate plummets by approximately 5 percentage points, and it continues to drop to around 0.85 by List 5. After this initial steep decline, the Hit Rate continues a more gradual but steady downward trend, with minor fluctuations, until it reaches its nadir of approximately 0.83–0.84 in the final lists of the initial phase. This trajectory means that for every list after the first, the probability of correctly recognizing a target was substantially lower than the probability of correctly rejecting a foil, a key pattern that any comprehensive model must capture.

**Figure 3.4.1: Between-List Initial Test Performance**_(Insert plot similar to the top-left panel of Prediction 1 or Figure 3 from the data, showing Hit Rate (target/TRUE) and CR Rate (foil/FALSE) across the 10 lists.)_

To formally test these visual trends, a GLMM was fitted to the trial-level accuracy data. The model predicted correctness from the fixed effects of Item Type (Target vs. Foil), List Number (treated as a continuous variable, centered), and their interaction. The statistical results robustly confirmed the pattern observed in the figure. A significant main effect of Item Type was found (e.g., _β_ = -0.45, _SE_ = 0.08, _z_ = -5.6, _p_ < .001), reflecting the overall higher accuracy for foils than for targets after the first list. More importantly, the model revealed a highly significant interaction between Item Type and List Number (e.g., _β_ = -0.12, _SE_ = 0.02, _z_ = -6.0, _p_ < .001). Simple slopes analysis to decompose this interaction confirmed that there was a significant negative linear effect of List Number on the log-odds of a correct response for target trials (a declining Hit Rate), whereas the slope for foil trials was flat and non-significant.

This dissociation is a classic signature of proactive interference. The stability of the CR rate is a direct consequence of the experimental design, which used entirely novel foils in each initial test. Because foils were never repeated, participants could effectively adopt a decision strategy based on a global familiarity signal: any picture that felt entirely novel could be confidently rejected. There was no need to engage in a more difficult source memory judgment (e.g., "Was this on the current list or a previous one?").

The decline in the Hit Rate, therefore, cannot be attributed to a general decline in motivation, attention, or overall memory capacity. Instead, it points specifically to an increasing difficulty in the retrieval process for target items. As the number of pictures stored in memory increased with each successive list, the memory system faced a greater challenge in confirming the presence of a specific item from the _current_ list. According to context-based memory theories, including the REM framework, the presentation of a target item from List N initiates a search of memory. This search cue is composed of the item's content features and the current context. As the experiment progresses, the number of stored memory traces that are similar in content and context grows. Traces from previous lists (e.g., List N-1, N-2) are activated alongside the correct trace from List N, creating "context noise" that interferes with the retrieval process. This competition reduces the diagnostic evidence for the item's membership in the current list, lowering the calculated likelihood ratio (or "odds" in REM terminology) and consequently decreasing the probability of a "hit". The model's ability to capture this phenomenon is rooted in its assumption that traces from prior lists can be activated during the memory search, an idea visually supported by model-generated plots showing that as lists progress, a greater proportion of activated traces come from prior lists.

Response time data provide strong converging evidence for this interpretation. An LMM on the log-transformed RTs of correct responses revealed a significant interaction between Item Type and List Number. For correct rejections, response times remained fast and highly stable across the ten lists. For correct hits, however, response times showed a significant increase from List 2 onwards. Participants became progressively slower to correctly identify targets as the experiment continued. This slowing of responses indicates that as proactive interference accumulated, the decision process for targets became more difficult, effortful, and time-consuming, consistent with a theoretical process of needing to resolve increasing competition among a growing set of similar memory traces.

---

#### **3.4.2. Within-List Effects: Serial Position and Output Interference**

Having established the global trend of accumulating proactive interference across lists, we now turn to the micro-dynamics of performance within a single, typical study-test block. These analyses, which are averaged across all ten lists, reveal how memory is shaped by the temporal position of items during both encoding (the study phase) and retrieval (the test phase). These within-list patterns provide a second, orthogonal set of constraints for any viable memory model.

**3.4.2.1. Study Position Effects: The Serial Position Curve**

The serial position curve is a fundamental and extensively documented phenomenon in memory research, describing the relationship between an item's ordinal position in a study list and its subsequent probability of being remembered. To examine this effect in our data, we plotted the Hit Rate for target items as a function of their original study position, from 1 to 20. The left panel of Figure 3.4.2 shows the resulting curve. The data reveal a classic, albeit somewhat noisy, serial position curve characterized by robust primacy and more modest recency effects.

**Figure 3.4.2: Within-List Initial Test Performance by Study and Test Position**_(Insert plot similar to Figure 1 from the presentation or the data, showing the Initial Study Position plot on the left and the Initial Test Position plot on the right.)_

The **primacy effect** is evident in the markedly elevated performance for the first few items presented in each study list. The very first item, in particular, exhibits a Hit Rate of nearly 94%, a level of performance that is significantly higher than that for any item in the middle of the list. This initial advantage diminishes over the next several positions, with performance gradually declining to a stable baseline. The primacy effect is traditionally attributed to the greater cognitive resources available for processing early items. Before working memory becomes loaded with other items, the first few pictures can be encoded more deeply and with less interference from other list items, perhaps benefiting from additional rehearsal or attentional allocation. Within the REM framework, this could be conceptualized as these early items being encoded with a higher number of features, resulting in stronger and more distinctive memory traces that are more easily retrieved later.

The **recency effect** is visible as a noticeable, albeit smaller, uptick in performance for the final few items studied. Items presented in positions 18, 19, and 20 show a higher Hit Rate than those from the central portion of the list, with performance rising back toward 88-90%. The recency effect is often explained by the continued availability of these items in a short-term memory buffer at the time of the test. In this experiment, a 16-second arithmetic distractor task was intentionally included between study and test to disrupt simple maintenance in a phonological loop. However, the complex visual and conceptual information from the last few pictures may have remained more activated or accessible than items from the middle of the list. From a context-based perspective, the recency effect arises from the high degree of similarity between the temporal context present at the end of the study phase and the context reinstated at the beginning of the test phase. This contextual overlap provides a powerful retrieval cue that facilitates access to the most recently encoded traces.

To formally test the U-shaped nature of this curve, a GLMM was fitted to the target accuracy data with orthogonal polynomial contrasts for Study Position (centered). The results confirmed the visual pattern, revealing significant linear and quadratic components. This robust replication of the serial position curve for picture recognition provides another critical benchmark for the model, as it must possess mechanisms that can account for the differential encoding strength or retrievability of items based on their temporal position within a distinct study episode.

**3.4.2.2. Test Position Effects and the Absence of Output Interference**

Output interference (OI) refers to the phenomenon where the act of retrieving some information from memory impairs the ability to subsequently retrieve other, related information. In a typical recognition test, this would manifest as a decline in performance as the test progresses. Previous research, particularly with verbal stimuli, has often found strong evidence for OI. We therefore analyzed both Hit Rates and Correct Rejection rates as a function of their position within the 20-trial test block to see if this pattern held for picture stimuli in our paradigm.

The results, depicted in the right panel of Figure 3.4.2, are striking and run directly contrary to a simple OI prediction. For picture recognition in this paradigm, there is **no evidence of output interference for target items**; in fact, the data show a clear pattern of facilitation. The Hit Rate (the lower, light blue line) starts at its lowest point, with an accuracy below 80% for the first test trial. From this low starting point, the Hit Rate systematically and substantially _increases_ as the test continues, climbing steadily to a peak of nearly 90% by the end of the 20-trial test block. This improvement of over 10 percentage points from the beginning to the end of the test is the opposite of what a standard output interference account would predict.

Concurrently, the Correct Rejection rate (the upper, yellow line) exhibits an opposing trend. It begins at a very high level of accuracy, around 96% for the first few test trials, and then shows a slight but systematic decrease across the test block, finishing at approximately 93%. This means that participants became slightly more likely to make a false alarm to a new item as the test progressed. A key feature of this dynamic is the **convergence** of the two performance lines: the large gap in accuracy between CRs and Hits observed at the beginning of the test progressively narrows as the test continues. The average performance, represented by the black line in the figure, remains relatively flat because the strong increase in Hit Rate is largely canceled out by the slight decrease in the Correct Rejection rate.

A GLMM predicting accuracy from Item Type, Test Position (continuous, centered), and their interaction statistically confirmed these observations. The model yielded a significant interaction between Item Type and Test Position. Follow-up analyses of the simple slopes revealed a significant _positive_ effect of Test Position on the accuracy for targets (an increasing Hit Rate) and a significant _negative_ effect of Test Position on the accuracy for foils (a decreasing Correct Rejection rate).

This complex pattern refutes a simple account of output interference and points toward more dynamic processes occurring during the test phase itself. The pronounced improvement in Hit Rate suggests a form of **retrieval-based facilitation** or **context reinstatement**. The first few test items, whether they are hits or correct rejections, may serve to "warm up" or progressively reinstate the unique context associated with the preceding study list. Each successful retrieval of a target might strengthen not only the trace of that specific item but also the shared representation of the list's overall context. This enriched and reinstated context then acts as a more effective cue for subsequent memory searches, making it easier and more likely to retrieve other targets from the same list.

Explaining the concurrent decrease in the Correct Rejection rate requires considering the memory-updating consequences of testing. According to modern memory models like REM, every test trial can result in the storage of new information or the modification of existing information. When a foil is presented and correctly rejected, a new memory trace for that foil is nevertheless created and stored in memory. When a target is correctly identified, its existing trace is retrieved and may be strengthened by adding features from the test probe. The simple effect of strengthening a trace would be to make it less similar to other items, which should, in theory, _increase_ the correct rejection of later foils because the memory system becomes more cluttered with distinct, high-fidelity traces. This prediction is contrary to the observed data.

However, the extended REM model used for this work incorporates a crucial additional mechanism: a first-stage, context-based filter that pre-activates only those memory traces that are a good match to the test probe's context. The process of strengthening a target trace modifies its feature composition. This modification might paradoxically make the strengthened trace a _poorer_ match for the overall list context filter on subsequent trials. If fewer old traces are activated by this context filter as testing proceeds, the pool of evidence supporting an "old" decision diminishes, which could lead to a slight decrease in the overall odds computed for new items. This would make it marginally more difficult to reject them, thus lowering the Correct Rejection rate. The observed pattern is therefore likely the net result of several competing processes: the facilitative effect of context reinstatement on target retrieval, and the complex consequences of memory updating (storing new foil traces and strengthening target traces) as seen through a context-based filtering mechanism. A concurrent shift in the decision criterion, perhaps becoming more lenient as the test progresses and the list context becomes more familiar, could also contribute to this pattern.

---

#### **3.4.3. Response Time Analyses: A Window into Decision Dynamics**

Analyses of response times provide a continuous measure of processing effort and can help to further disambiguate the cognitive processes underlying the observed accuracy patterns. If a decision is more difficult, it should not only be less accurate but should also take longer to make. We therefore conducted LMMs on the log-transformed RTs of correct responses.

The RT data fully corroborated the interpretations of proactive interference from the accuracy data. Across the ten lists, the RTs for correct rejections remained uniformly fast and stable. However, the RTs for correct hits showed a significant increase as a function of list number. This finding reinforces the conclusion that target retrieval became a more effortful and time-consuming cognitive operation as interference from prior lists mounted.

Most critically, the RT data for the within-list test phase provided decisive support for the context reinstatement/facilitation hypothesis over an output interference account. A significant interaction between Item Type and Test Position was found for RTs. The RTs for correct hits became significantly _faster_ as the test block progressed. This indicates that decisions about targets not only became more accurate but also easier and more efficient, a finding that is irreconcilable with output interference. In contrast, the RTs for correct rejections showed a slight but significant _increase_ across the test block. This suggests that rejecting novel items became marginally more difficult or less automatic as the test proceeded, a finding consistent with the accuracy data and the theoretical account of accumulating foil traces altering the state of the memory system.

---

#### **3.4.4. Summary of Initial Test Phase Results**

The detailed analyses of the initial study-test phase have revealed a rich, complex, and highly informative set of behavioral patterns that characterize how recognition memory operates in a multi-list paradigm with picture stimuli. The key findings, which serve as primary targets for the computational model, can be summarized as follows:

1. **Robust and Selective Proactive Interference:** There is unequivocal evidence for the build-up of proactive interference across the ten experimental lists. This interference specifically impairs the ability to retrieve target items from the current list, as reflected in a systematic decline in Hit Rates and an increase in RTs for hits. Crucially, this effect is highly selective, as the ability to reject entirely novel foils remains fast and accurate throughout.
    
2. **Classic Study Position Effects:** Within each study list, recognition performance is strongly modulated by an item's original temporal position. The data exhibit a classic serial position curve, with a strong primacy effect for the first few items and a more modest recency effect for the final items, indicating that items at the temporal boundaries of an episode are encoded more effectively or are more readily accessible.
    
3. **A Reversal of Output Interference at Test:** Contrary to standard findings with verbal stimuli, there is no evidence of output interference during the recognition test. Instead, the data reveal a powerful facilitation effect for target items: Hit Rates systematically improve, and response times decrease, as the test progresses. This suggests that the retrieval process itself serves to reinstate the list context, which in turn facilitates subsequent recognition judgments. This facilitation is accompanied by a slight decrease in the accuracy of rejecting foils, pointing to the complex consequences of continuously updating memory during testing.
    

Together, these findings paint a detailed and nuanced picture of the role of context in recognition memory. They highlight how context can be a source of interference when distinguishing between episodes (the PI effect) but also a source of facilitation when operating within a single, coherent episode (the test-position effect). This multifaceted pattern of results provides a stringent and challenging set of empirical constraints for the development and validation of the extended REM model in the following chapter.