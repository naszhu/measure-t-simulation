
## daily note
-  Hits and CR dynamics [allDay:: true]

  

# 用户问题

say this in a better way,

  

- T Hits increase: easy to undersand; 1st stage passing same number traces from current list (at list n) ; but accumulates on past lists number of activations (traces from n-1; n-2; n-3..etc) ; causing N increase, odds decrease, Hits decrease.

- Fb bad foil CR decrease: 1st passing actually, also same number of traces from n-1 list; The increase traces in prior list, means increasing of accumulating of lists n-2 to n-3, ... recursivly, but not increasing number of activations from list n-1 (if UC and C keeps constant ; and other factors constant.); ==&gt; so, still, same number of trace containing Fb (with a high likelihood), but increase number of accumulation of list length, base N increases; thus increase prob of answer NEW, thus CR goes up.

# 回答

Here’s a clearer phrasing:

  
  

- **Target hit rate decreases**

In the first retrieval stage, the number of traces passed from the current list (list n) remains fixed, but activations from all earlier lists (n–1, n–2, n–3, …) continue to accumulate. As the total trace count N grows, the odds of sampling a target trace drop, so the hit rate falls.

- **Correct‐rejection rate for bad foils increases**

Again, the number of traces carried over from list n–1 stays constant. However, because activations from even earlier lists (n–2, n–3, …) keep piling on (with UC, C, and other parameters held constant), the larger pool N makes a “new” response more likely—so the correct‐rejection (CR) rate for bad foils goes up.

# 用户问题

Uh, I shouldn't use the word sampling. I meant

  

In first stage, the number of traces passed from the current list (list n) remains fixed, but activations from all earlier lists (n–1, n–2, n–3, …) continue to accumulate. Trace from current list_n contains target T. As the total trace count N grows, the overall odds of a target trace drop, so the hit rate falls. ==&gt; I'm just talking about list-length effect, in second stage odds calculations.

  

And the same thing applied exactly to Fb. As a first glance, it seems "activating more prior lists traces" should be associated with a drop of CR of Fb, but I was saying, actually not because the number of activated traces of the list that contains the current Fb (in list n-1) of each list (when at list n), do not change; and so, the increasing N is associated with more New response, thus higher CR;

# 回答

Here’s a tighter phrasing focused on the second‐stage odds calculation:

  
  

- **Target hit rate (H) decreases**

In Stage 1, the number of activated traces from the current list $n$ (all containing the target) is held constant, while activations from earlier lists ($n\!-\!1, n\!-\!2, \dots$) keep accumulating as list length grows. In Stage 2’s odds ratio, that larger total trace count $N$ sits in the denominator—so the odds of a target match drop and the hit rate falls.

- **Correct‐rejection rate for bad foils (CR) increases**

Similarly, the count of activated traces from the list containing a given foil (list $n\!-\!1$) remains fixed, but older lists’ activations keep piling on. Because $N$ grows, the baseline probability of a “new” response in Stage 2 rises—so CR goes up.

# 用户问题

uh, whats the relation between my advisor adn my rhinking? why i thik i am talking about familarity indeed but he says im talking about recall?

# 回答

Your advisor is reading your description through their own theoretical lens—and in the two-stage REM framework, each stage maps onto a different kind of “memory”:

  
  

1. **Stage 1 = Familiarity (global match):**

You pass a fixed number of traces from the current list into a global‐match calculation (summing activations across all lists). That summed strength is what in many models is called *familiarity*.

2. **Stage 2 = Recollection or “recall” (content‐based odds):**

Once a probe survives Stage 1, you then compare its specific features against stored feature vectors—that’s a content‐based odds ratio, which corresponds to *recollection* (or recall of specific details).

  

When you talk about “number of activated traces” and the way odds change when you accumulate traces from earlier lists, you’re describing how the **content odds** shift in Stage 2—and that’s why your advisor hears “recall.” You feel you’re talking about familiarity because you’re focused on how many traces go into the match, but your advisor is focusing on *what you do with those traces*—the odds calculation over their feature content—which in REM is the recollection stage.

  
  

**How to clear it up with your advisor:**

  
  

- Label the stages explicitly: “In Stage 1 (familiarity/global‐match) …” versus “In Stage 2 (recollection/feature‐odds) ….”

- Point out that the list‐length effect you’re describing arises in Stage 2’s odds ratio, even though the sum of traces comes from Stage 1.

  

That way you both can agree on which process—global versus content—is doing the work you’re analyzing.

# 用户问题

i don't know waht you are talking about at all, give me math repres

# 回答

Let

  
  

$$

k_{n}=\#\text{activated traces from list }n,\qquad

k_{&lt;n}=\sum_{j=1}^{n-1}k_{j},\qquad

N=k_{n}+k_{&lt;n}.

$$

  
  

**Stage‐2 odds for a target**

  
  

$$

O_{T}

=\frac{k_{n}}{N}

\quad\Longrightarrow\quad

P(\text{“old”}\mid T)

=\frac{O_{T}}{1+O_{T}}

=\frac{k_{n}}{k_{n}+N}

=\frac{k_{n}}{2\,k_{n}+k_{&lt;n}}.

$$

  
  

As $k_{&lt;n}$ grows, $N$ grows ⇒ $O_{T}$ falls ⇒ hit rate $P(\text{old}\mid T)$ falls.

  
  
  

**Stage‐2 odds for a foil in list $n\!-\!1$**

  
  

$$

k_{f}=k_{n-1}\quad(\text{constant}),\qquad

N'=k_{f}+k_{&lt;\,n-1},

$$

  
  

$$

O_{F}

=\frac{k_{f}}{N'}

\quad\Longrightarrow\quad

P(\text{“new”}\mid F)

=1-\frac{O_{F}}{1+O_{F}}

=\frac{1}{1+O_{F}}

=\frac{N'}{k_{f}+N'}.

$$

  
  

As $k_{&lt;\,n-1}$ grows, $N'$ grows ⇒ $O_{F}$ falls ⇒ $P(\text{new}\mid F)$ (i.e. CR) rises.

# 用户问题

?? so isn't the odds just familarity?

# 回答

Not exactly. In REM, **familiarity** is the **sum** of match strengths over all traces, whereas the **odds** used in Stage 2 is a **ratio** of two such sums.

  
  
  

1. **Global‐match (familiarity)**

  

$$

F \;=\;\sum_{i=1}^{N} s(\text{probe},\text{trace}_i)

$$

  

where $s(\cdot,\cdot)$ is the similarity of the probe to trace $i$. $F$ is a single scalar “familiarity” signal.

2. **Stage 2 odds**

Split that sum into the part coming from the “signal” class vs. the “noise” class. For a target probe:

  

$$

F_T \;=\;\sum_{i\in\text{list }n} s_i,

\qquad

F_N \;=\;\sum_{i\notin\text{list }n} s_i,

$$

  

and the odds ratio is

  

$$

O_T \;=\;\frac{F_T}{F_N}

\quad\Longrightarrow\quad

P(\text{“old”}\mid T)

\;=\;\frac{O_T}{1 + O_T}.

$$

  

For a foil in list $n-1$, define

  

$$

F_F \;=\;\sum_{i\in\text{list }n-1} s_i,

\quad

F_{N'} \;=\;\sum_{i\notin\text{list }n-1} s_i,

$$

  

and

  

$$

O_F \;=\;\frac{F_F}{F_{N'}}

\quad\Longrightarrow\quad

P(\text{“new”}\mid F)

\;=\;\frac{1}{1 + O_F}.

$$

  
  

- **Familiarity** $=$ one sum $F$.

- **Odds** $=$ ratio of two sums $\;F_{\text{signal}}/F_{\text{noise}}$.

  

So the odds are **derived from** familiarity signals, but they are **not the same** as the raw familiarity.

# 用户问题

uh.. i feel ike all these are so abstract and hard to express to another person, like the comminication between me and my advisor.. i feel ike these are alll include so much abstract thinking. is it becuase that i just am abstract myself so i feel so , or this is truely abstract thinking?...(before actually writing down to math)

  

and.. do you think if my boyfrireds's thinking in his work include such abstraction as well?

# 回答

It really comes down to two things at once:

  
  

1. **The topic itself is inherently abstract.**

REM’s two‐stage odds calculations live in a high-dimensional feature space and involve sums-of-similarities and ratios-of-sums. Before you even write down the equations, you’re juggling sets of traces, activation counts, “signal vs. noise” partitions, and what those imply for familiarity and recollection. Any description of that process—whether in words or diagrams—feels “up in the clouds” because you’re talking about operations on distributions of memory traces, not concrete objects you can point to.

2. **Your personal style amplifies the abstraction.**

You’ve described yourself as someone who naturally thinks in multilayered, conceptual structures. You notice subtle distinctions, you see how small shifts in one parameter ripple through the rest of the system. That’s a strength for modeling—but it can make any explanation feel overloaded if your listener isn’t on exactly the same wavelength.

  
  

### Why it feels hard to “ground” before the math

  
  

- **Missing anchors.** Without a concrete analogy or simple example (e.g., “imagine you have 5 red cards and 95 blue cards…”), people have to translate every phrase into the underlying structure themselves.

- **Layered abstractions.** You’re moving from “what is a trace?” to “what is activation?” to “how do those activations combine?” each in rapid succession.

  

**What you can do:**

  
  

- **Pick a simple metaphor** (cards in a deck, beads in jars, coins in a fountain) and walk through one small list-length effect example step by step.

- **Draw a diagram** that shows “current-list” vs. “all-prior” pools, then overlay the odds ratio arrow. Even a rough sketch drastically reduces the verbal load.

- **Define just one term at a time** and check for alignment before moving on.

  
  

### What about your boyfriend’s abstraction?

  
  

His work as a criminal defense lawyer certainly involves abstraction—he’s constantly translating complex facts into legal categories (“mens rea,” “exculpatory evidence,” “reasonable doubt”), weighing precedents, and anticipating counterarguments. But:

  
  

- **Different domains, different textures.** Legal abstractions often map onto real-world events (witness testimony, physical evidence) and established statutes, so they feel more concrete.

- **Lower dimensionality?** He typically juggles fewer “degrees of freedom” at once—maybe three or four legal issues—whereas you’re tracking tens or hundreds of features across multiple lists.

  

In short, **the model itself is abstract**, and **your own thinking style deepens that abstraction**. Your boyfriend also thinks abstractly, but his abstractions are anchored by cases, statutes, and narratives—so they feel less “floating in mid-air.”