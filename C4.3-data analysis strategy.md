Of course. Here is the continuation of your dissertation, section 4.3.

---

### **4.3. Data Analysis Strategy**

The data analysis strategy for Experiment 2 is designed to build directly upon the framework established for Experiment 1, while extending it to address the novel and central research questions posed by the mixed-foil design. The primary goal is to systematically investigate how recognition memory operates under conditions of high foil familiarity, where simple novelty detection is no longer a viable strategy. The introduction of foils drawn from the immediately preceding list necessitates a more nuanced analysis that focuses on participants' ability to make fine-grained source memory judgments and to discriminate between contexts. The analytical approach will therefore prioritize the comparison of different foil types, track learning and strategic adaptations across lists, and examine how a more complex learning history affects long-term memory.

All data processing, visualization, and statistical modeling will be conducted using the R programming language, leveraging the `tidyverse` suite for data management and the `lme4` package for fitting mixed-effects models. Data preprocessing and participant exclusion criteria will be identical to those used in Experiment 1 to ensure data quality and allow for direct comparison between the two experiments. This includes the removal of incomplete sessions and participants who fail to meet the 60% accuracy criterion on the final test, as well as the filtering of trials with extreme response times from latency analyses.

---

#### **Analysis of the Initial Study-Test Phase**

The initial phase of Experiment 2 is where the critical manipulation occurs, and the analysis is structured to fully explore its consequences. Unlike Experiment 1, where all foils were novel, the foils on any given list N (for N > 1) are a mix of entirely new pictures and "inherited foils" drawn from the various item types presented on list N-1. This requires a detailed breakdown of performance by both target and multiple foil types.

**Dependent Variables and Item Types:** The primary dependent variables remain recognition accuracy and correct response times. However, the accuracy analysis must now accommodate a more complex set of item categories, as depicted in the data from the SMP 2025 presentation:

- **Targets:** Pictures studied on the current list (list N). The accuracy measure is the **Hit Rate (H)**.
    
- **New Foils:** Pictures entirely new to the experiment. The accuracy measure is the **Correct Rejection (CR) rate**.
    
- **Inherited Foils:** Pictures that appeared on the immediately preceding list (list N-1) and are now presented as foils on list N. The CR rate for these items is the primary measure of list discrimination ability. This category will be further subdivided based on the item's history on list N-1:
    
    - **Inherited Foil - Last Target:** An item that was studied and tested as a target on list N-1. These are expected to be the most familiar and therefore most difficult foils to reject.
        
    - **Inherited Foil - Last Studied Only:** An item that was studied on list N-1 but was not included in the initial test phase.
        
    - **Inherited Foil - Last Foil:** An item that served as a foil on list N-1.

**Primary Analyses for the Initial Phase:** The analytical plan is designed to track how participants adapt to this challenging recognition environment over time.

1. **Discrimination of Foil Types:** The central analysis will involve comparing the Correct Rejection rates across the different foil categories. A GLMM will be used to predict the accuracy of "new" judgments, with Foil Type as the primary fixed effect. It is hypothesized that the CR rate will be highest for New Foils, reflecting their lack of familiarity. For the Inherited Foils, performance is expected to vary as a function of their prior-list familiarity, with the lowest CR rate predicted for foils that were previously targets, as these items have the strongest existing memory traces.
    
2. **Between-List Dynamics and Strategic Adaptation:** A key focus will be analyzing performance across lists 2 through 10 (as inherited foils only appear from list 2). We will specifically examine two critical patterns visible in the data:
    
    - **Criterion Shifts:** The data suggest that target hits and new foil correct rejections cross as lists continue. This implies that participants adjust their decision criterion in response to the massive increase in false alarms caused by the highly familiar inherited foils. We will model the accuracy for targets and new foils across lists to formally test for this interaction.
        
    - **Learning to Discriminate:** The data also show that the CR rate for all types of inherited foils improves as the lists continue. This suggests that participants get better at rejecting confusing foils from the prior list, a form of strategic learning. This may be due to an increased focus on encoding or retrieving list-specific context that can distinguish between list N and list N-1. We will model the accuracy of rejecting inherited foils as a function of list number to quantify this learning effect.
        
3. **Within-List Analyses:** Standard analyses of study position effects (primacy/recency) and test position effects (output interference) will be conducted, following the same procedures as in Experiment 1. This will allow for a direct comparison to see how the presence of familiar foils alters these fundamental within-list dynamics.
    

**Statistical Approach:** The primary statistical tool will be GLMMs predicting trial-level accuracy. A comprehensive model for the initial phase will include Item Type (as a multi-level factor: Target, New Foil, Inherited-Target, etc.), List Number (as a continuous predictor), and their interaction as fixed effects. The models will also include random intercepts for participants and items to account for the nested data structure.

---

#### **Analysis of the Final Test Phase**

The final test in Experiment 2 is significantly more complex than in Experiment 1, as items now have varied and multi-layered learning histories, including multiple appearances across different lists and in different roles. The analysis must account for this complexity to understand the factors contributing to long-term retention.

**Dependent Variables and Item Categories:** The primary dependent variable is the Hit Rate for items designated as targets in the final test. These targets are drawn from the full range of items presented during the initial phase. As shown in the data , items will be categorized based on their complete history, with a particular focus on the total number of occurrences (one, two, or three times) an item was presented during the initial phase.

**Primary Analyses for the Final Phase:**

1. **Effect of Item History and Frequency:** The main analysis will focus on how an item's cumulative history impacts its final recognition accuracy. A GLMM will be used to predict hit rates based on a factor representing the item's specific history and frequency of occurrence. We will specifically test the hypothesis that accuracy increases with the number of exposures during the initial phase. The detailed performance patterns seen in the data will serve as the primary target for this analysis, allowing for comparisons between, for example, an item seen once as a target versus an item seen once as a foil.
    
2. **Long-Term Serial Position Effects:** We will analyze final test accuracy as a function of the item's original list number (1â€“10) to investigate the shape of the long-term retention curve. As suggested by the data , we expect to see a recency effect, indicating that the dynamic temporal context signal remains a potent retrieval cue even in this more complex experiment.
    
3. **Final Test Output Interference:** To assess retrieval dynamics during the final test itself, we will analyze performance as a function of an item's ordinal position within the final test block. Following the clear pattern in the data , we expect to find strong output interference, with accuracy for all item types declining as the lengthy final test progresses. This will be modeled using a GLMM with Final Test Position as a continuous predictor.
    

**Comparison with Experiment 1:** A crucial component of the overall analytical strategy will be the direct comparison of key findings from Experiment 2 with the baseline results from Experiment 1. This will allow us to isolate the impact of introducing familiar foils. Specifically, we will compare the magnitude of proactive interference, the within-list test dynamics (i.e., is the facilitation effect still present?), and the final test retention patterns. This comparison will be essential for understanding how the need for list-level discrimination fundamentally alters memory encoding, retrieval, and decision strategies.
